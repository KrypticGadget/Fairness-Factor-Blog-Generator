This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repopack on: 2024-11-02T08:51:20.225Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
.env.example
.github/workflows/codeql.yml
.github/workflows/deploy.yml
.github/workflows/main.yml
.gitignore
.streamlit/config.toml
.streamlit/secrets.toml.example
app.py
config.py
Dockerfile
init_db.py
llm/__init__.py
llm/article_draft.py
llm/editing_criteria.py
llm/final_article.py
llm/image_description.py
llm/llm_client.py
llm/seo_generation.py
llm/topic_campaign.py
pages/__init__.py
pages/article_draft.py
pages/editing_criteria.py
pages/final_article.py
pages/image_description.py
pages/seo_generation.py
pages/topic_campaign.py
pages/topic_research.py
Procfile
prompts/article_draft.txt
prompts/editing_criteria.txt
prompts/final_article.txt
prompts/image_description.txt
prompts/seo_generation.txt
prompts/topic_campaign.txt
prompts/topic_research.txt
README.md
requirements.txt
scripts/rotate_jwt_key.py
static/styles.css
test_auth.py
test_mongodb_connection.py
test_mongodb.py
tests/test_mongodb.py
utils/__init__.py
utils/auth_handler.py
utils/auth.py
utils/data_handlers.py
utils/key_rotation.py
utils/mongo_manager.py
utils/prompt_handler.py
utils/session_manager.py

================================================================
Repository Files
================================================================

================
File: .env.example
================
# Create a new .env.example file
cat > .env.example << EOL
# MongoDB Configuration
MONGODB_URI=mongodb+srv://<username>:<password>@<cluster>.mongodb.net/<database>?retryWrites=true&w=majority

# Authentication
JWT_SECRET_KEY=your_jwt_secret_key_here

# LLM API
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Application Settings
APP_NAME=Fairness Factor Blog Generator
APP_DOMAIN=fairnessfactor.com
ADMIN_EMAIL=admin@fairnessfactor.com
ADMIN_PASSWORD=your_secure_admin_password
EOL

# Ensure .env is in .gitignore
echo ".env" >> .gitignore

================
File: .github/workflows/codeql.yml
================
# .github/workflows/codeql.yml
name: "CodeQL"

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '30 1 * * 0'

jobs:
  analyze:
    name: Analyze
    runs-on: ubuntu-latest
    permissions:
      actions: read
      contents: read
      security-events: write

    strategy:
      fail-fast: false
      matrix:
        language: [ 'python' ]

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Initialize CodeQL
      uses: github/codeql-action/init@v2
      with:
        languages: ${{ matrix.language }}

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v2

================
File: .github/workflows/deploy.yml
================
# .github/workflows/deploy.yml
name: Deploy to Streamlit Cloud

on:
  push:
    branches: [ main ]
  schedule:
    - cron: '0 0 1 * *'  # Monthly key rotation

jobs:
  deploy:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v2
    
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Deploy to Streamlit Cloud
      env:
        STREAMLIT_CREDENTIALS: ${{ secrets.STREAMLIT_CREDENTIALS }}
        MONGODB_URI: ${{ secrets.MONGODB_URI }}
        JWT_SECRET_KEY: ${{ secrets.JWT_SECRET_KEY }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      run: |
        streamlit run app.py &

================
File: .github/workflows/main.yml
================
# .github/workflows/main.yml
name: CI/CD Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v2
    
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov
    
    - name: Run tests with coverage
      env:
        MONGODB_URI: ${{ secrets.MONGODB_URI }}
        JWT_SECRET_KEY: ${{ secrets.JWT_SECRET_KEY }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      run: |
        pytest --cov=./ --cov-report=xml
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v2
      with:
        file: ./coverage.xml
        fail_ci_if_error: true

  deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v2
    
    - name: Deploy to Streamlit Cloud
      env:
        STREAMLIT_API_KEY: ${{ secrets.STREAMLIT_API_KEY }}
      run: |
        curl -X POST https://api.streamlit.io/v1/apps \
          -H "Authorization: Bearer $STREAMLIT_API_KEY" \
          -H "Content-Type: application/json" \
          -d '{
            "gitRepo": "'"$GITHUB_REPOSITORY"'",
            "gitBranch": "main",
            "mainModule": "app.py",
            "customDomain": "blog-generator.fairnessfactor.com"
          }'

================
File: .gitignore
================
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
venv/
ENV/

# Environment variables
.env
.env.local
.env.*.local
.streamlit/secrets.toml

# IDE configurations
.idea/
.vscode/
*.swp
*.swo

# Project-specific files
data/outputs/*
!data/outputs/.gitkeep
*MASTER_CONTENTS.md

# System files
.DS_Store
Thumbs.db

# Test coverage files
.coverage
coverage.xml
htmlcov/

# Logs
*.log

================
File: .streamlit/config.toml
================
# .streamlit/config.toml

[server]
port = 8501
enableCORS = true
enableXsrfProtection = true
address = "localhost"  # Changed from 0.0.0.0

[browser]
serverAddress = "localhost"  # Changed from 0.0.0.0
gatherUsageStats = false

[theme]
primaryColor = "#0077BD"
backgroundColor = "#00263E"
secondaryBackgroundColor = "#005587"
textColor = "#FFFFFF"
font = "sans serif"

[logger]
level = "info"
messageFormat = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

================
File: .streamlit/secrets.toml.example
================
# .streamlit/secrets.toml.example
[mongodb]
uri = "${MONGODB_URI}"

[jwt]
secret_key = "${JWT_SECRET_KEY}"

[anthropic]
api_key = "${ANTHROPIC_API_KEY}"

[app]
name = "Fairness Factor Blog Generator"
emoji = "⚖️"
domain = "fairnessfactor.com"

================
File: app.py
================
# app.py
import streamlit as st
import asyncio
import os
from datetime import datetime
import logging
from typing import Optional, Dict, Any
import base64
from config import Config
from test_mongodb import test_connection
from utils.auth import AsyncAuthHandler
from utils.mongo_manager import AsyncMongoManager, get_db_session
from utils.data_handlers import (
    AsyncBlogContentHandler,
    AsyncFileHandler, 
    AsyncAnalyticsHandler
)
from utils.prompt_handler import AsyncPromptHandler
from utils.session_manager import AsyncSessionManager
from llm.llm_client import AsyncLLMClient

# Import page modules
from pages.topic_research import topic_research_page
from pages.topic_campaign import topic_campaign_page
from pages.article_draft import article_draft_page
from pages.editing_criteria import editing_criteria_page
from pages.final_article import final_article_page
from pages.image_description import image_description_page
from pages.seo_generation import seo_generation_page

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Ensure required directories exist
os.makedirs('output/articles', exist_ok=True)
os.makedirs('prompts', exist_ok=True)

def load_css(css_file: str) -> None:
    """Load CSS file"""
    try:
        with open(css_file) as f:
            st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)
    except Exception as e:
        logger.error(f"Error loading CSS file: {str(e)}")
        st.error(f"Error loading CSS file: {str(e)}")

def load_image(image_path: str) -> Optional[str]:
    """Load and encode image file"""
    try:
        with open(image_path, "rb") as f:
            return base64.b64encode(f.read()).decode()
    except Exception as e:
        logger.error(f"Error loading image: {str(e)}")
        return None

def display_logo(context: str = 'main') -> None:
    """Display Fairness Factor logo with context-specific styling"""
    logo_path = os.path.join('assets', 'FairnessFactorLogo.png')
    if os.path.exists(logo_path):
        logo_data = load_image(logo_path)
        if logo_data:
            container_class = 'logo-container-login' if context == 'login' else 'logo-container-main'
            st.markdown(f"""
                <div class="{container_class}">
                    <img src="data:image/png;base64,{logo_data}" alt="Fairness Factor Logo"/>
                </div>
            """, unsafe_allow_html=True)
    else:
        logger.warning("Logo file not found")

class AppState:
    """Application state management"""
    def __init__(self):
        self.loop = None
        self.mongo_manager = None
        self.initialized = False

    async def initialize(self):
        """Initialize application state"""
        if not self.initialized:
            try:
                # Initialize MongoDB connection
                self.mongo_manager = AsyncMongoManager()
                
                # Initialize session state
                if 'initialized' not in st.session_state:
                    async with get_db_session() as (client, db, fs):
                        st.session_state.db_handlers = {
                            'blog': AsyncBlogContentHandler(db),
                            'file': AsyncFileHandler(fs),
                            'analytics': AsyncAnalyticsHandler(db)
                        }
                        st.session_state.auth_handler = AsyncAuthHandler(db)
                        st.session_state.session_manager = AsyncSessionManager(db)
                        st.session_state.prompt_handler = AsyncPromptHandler(db)
                        st.session_state.llm_client = AsyncLLMClient()
                        st.session_state.initialized = True
                
                self.initialized = True
            except Exception as e:
                logger.error(f"Initialization error: {str(e)}")
                raise

async def run_app():
    """Main application runner"""
    app_state = AppState()
    await app_state.initialize()

    # Configure Streamlit page
    st.set_page_config(
        page_title="Fairness Factor Blog Generator",
        page_icon="⚖️",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # Load styling
    load_css('static/styles.css')

    # Authentication flow
    if 'user_token' not in st.session_state:
        display_logo('login')
        with st.form("login_form"):
            email = st.text_input("Email", placeholder="example@fairnessfactor.com")
            password = st.text_input("Password", type="password")
            if st.form_submit_button("Sign In"):
                success = await st.session_state.auth_handler.login(email, password)
                if success:
                    st.session_state.user_token = success
                    st.experimental_rerun()
    else:
        user = await st.session_state.auth_handler.verify_token(st.session_state.user_token)
        if not user:
            for key in st.session_state.keys():
                del st.session_state[key]
            st.experimental_rerun()
        
        # Main application UI
        display_logo('main')
        
        # Sidebar navigation
        with st.sidebar:
            st.write(f"Welcome, {user['name']}")
            if st.button("Sign Out"):
                for key in st.session_state.keys():
                    del st.session_state[key]
                st.experimental_rerun()

            pages = [
                'Topic Research',
                'Topic Campaign',
                'Article Draft',
                'Editing Criteria',
                'Final Article',
                'Image Description',
                'SEO Generation'
            ]
            
            page = st.radio("Navigation", pages)

        # Page routing
        try:
            if page == 'Topic Research':
                await topic_research_page(
                    st.session_state.db_handlers,
                    st.session_state.llm_client,
                    st.session_state.prompt_handler
                )
            elif page == 'Topic Campaign':
                await topic_campaign_page(
                    st.session_state.db_handlers,
                    st.session_state.llm_client,
                    st.session_state.prompt_handler
                )
            # Add other page handlers similarly...
            
        except Exception as e:
            logger.error(f"Page error: {str(e)}")
            st.error(f"An error occurred: {str(e)}")

def main():
    """Application entry point"""
    # Set up event loop policy for Windows
    if os.name == 'nt':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

    # Create and set event loop
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)

    try:
        # Run the application
        loop.run_until_complete(run_app())
    except Exception as e:
        logger.error(f"Application error: {str(e)}")
        st.error("An unexpected error occurred")
    finally:
        loop.close()

if __name__ == "__main__":
    main()

================
File: config.py
================
# E:\Kryptic Gadget Github Repos\Fairness-Factor-Blog-Generator\config.py
import streamlit as st
import os
from typing import Optional
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

def get_secret(key: str) -> Optional[str]:
    """Get secret from Streamlit secrets or environment variables"""
    try:
        # Try Streamlit secrets first
        return st.secrets[key]
    except:
        # Fall back to environment variables
        return os.getenv(key)

class Config:
    MONGODB_URI = get_secret("MONGODB_URI")
    JWT_SECRET_KEY = get_secret("JWT_SECRET_KEY")
    ANTHROPIC_API_KEY = get_secret("ANTHROPIC_API_KEY")
    
    @classmethod
    def validate(cls):
        """Validate all required configuration is present"""
        missing = []
        for attr in ['MONGODB_URI', 'JWT_SECRET_KEY', 'ANTHROPIC_API_KEY']:
            if not getattr(cls, attr):
                missing.append(attr)
        if missing:
            raise ValueError(f"Missing required configuration: {', '.join(missing)}")

================
File: Dockerfile
================
# Dockerfile
FROM python:3.9-slim

WORKDIR /app

# Install system dependencies
COPY packages.txt .
RUN apt-get update && cat packages.txt | xargs apt-get install -y

# Install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose Streamlit port
EXPOSE 8501

# Health check
HEALTHCHECK CMD curl --fail http://localhost:8501/_stcore/health

# Run the application
ENTRYPOINT ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]

================
File: init_db.py
================
import asyncio
from motor.motor_asyncio import AsyncIOMotorClient
from datetime import datetime
import bcrypt
import logging
from typing import List, Dict

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def init_collections(uri: str):
    """Initialize database collections with required indexes"""
    try:
        client = AsyncIOMotorClient(uri)
        db = client.fairness_factor_blog
        
        # Required collections
        collections = {
            'users': [
                [('email', 1)],  # Unique index on email
                [('created_at', -1)]
            ],
            'blog_content': [
                [('user_email', 1)],
                [('type', 1)],
                [('created_at', -1)]
            ],
            'analytics': [
                [('user_email', 1)],
                [('activity_type', 1)],
                [('timestamp', -1)]
            ],
            'sessions': [
                [('user_email', 1)],
                [('active', 1)],
                [('created_at', -1)]
            ],
            'jwt_keys': [
                [('created_at', -1)],
                [('is_active', 1)]
            ]
        }
        
        # Create collections and indexes
        for coll_name, indexes in collections.items():
            logger.info(f"Setting up collection: {coll_name}")
            
            # Create collection if it doesn't exist
            if coll_name not in await db.list_collection_names():
                await db.create_collection(coll_name)
            
            # Create indexes
            for index in indexes:
                await db[coll_name].create_index(index)
        
        # Create default admin user if not exists
        admin_email = 'zack@fairnessfactor.com'
        if not await db.users.find_one({'email': admin_email}):
            salt = bcrypt.gensalt()
            password = "1122Kryptic$"  # Change this in production!
            hashed = bcrypt.hashpw(password.encode('utf-8'), salt)
            
            await db.users.insert_one({
                'email': admin_email,
                'password': hashed,
                'name': 'Admin User',
                'role': 'admin',
                'created_at': datetime.now(),
                'created_by': 'system'
            })
            logger.info("Created default admin user")
        
        logger.info("✅ Database initialization complete!")
        return True
        
    except Exception as e:
        logger.error(f"❌ Database initialization failed: {str(e)}")
        return False
        
    finally:
        client.close()

if __name__ == "__main__":
    # Get MongoDB URI from environment or use default
    from dotenv import load_dotenv
    import os
    
    load_dotenv()
    uri = os.getenv('MONGODB_URI')
    
    if not uri:
        logger.error("MongoDB URI not found in environment variables")
        exit(1)
    
    asyncio.run(init_collections(uri))

================
File: llm/__init__.py
================
from .llm_client import AsyncLLMClient
from .topic_campaign import generate_topic_campaign
from .article_draft import generate_article_draft
from .editing_criteria import generate_editing_suggestions
from .final_article import generate_final_article
from .image_description import generate_image_description
from .seo_generation import generate_seo_content

__all__ = [
    'AsyncLLMClient',
    'generate_topic_campaign',
    'generate_article_draft',
    'generate_editing_suggestions',
    'generate_final_article',
    'generate_image_description',
    'generate_seo_content'
]

================
File: llm/article_draft.py
================
import logging
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)

async def generate_article_draft(
    topic: str,
    structure: str,
    llm_client: Any,
    prompt_handler: Any,
    user_email: str
) -> Optional[Dict[str, Any]]:
    """Generate article draft based on selected topic and structure"""
    try:
        draft_prompt = await prompt_handler.format_prompt(
            'article_draft',
            {
                'selected_topic': topic,
                'article_structure': structure
            }
        )
        
        if not draft_prompt:
            raise ValueError("Failed to format draft prompt")

        draft_content = await llm_client.generate_response(
            system_prompt="You are an AI writer creating blog articles for Fairness Factor...",
            user_prompt=draft_prompt,
            max_tokens=2000,
            user_email=user_email
        )
        
        return {
            'success': True,
            'draft': draft_content
        }
    except Exception as e:
        logger.error(f"Error generating article draft: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }

================
File: llm/editing_criteria.py
================
import logging
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)

async def generate_editing_suggestions(
    draft: str,
    criteria: Dict[str, str],
    llm_client: Any,
    prompt_handler: Any,
    user_email: str
) -> Optional[Dict[str, Any]]:
    """Generate editing suggestions based on provided criteria"""
    try:
        editing_prompt = await prompt_handler.format_prompt(
            'editing_criteria',
            {
                'article_draft': draft,
                'editing_criteria': '\n'.join(f"{k}: {v}" for k, v in criteria.items())
            }
        )
        
        if not editing_prompt:
            raise ValueError("Failed to format editing prompt")

        suggestions = await llm_client.generate_response(
            system_prompt="You are an AI editor reviewing Fairness Factor blog articles...",
            user_prompt=editing_prompt,
            max_tokens=1500,
            user_email=user_email
        )
        
        return {
            'success': True,
            'suggestions': suggestions
        }
    except Exception as e:
        logger.error(f"Error generating editing suggestions: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }

================
File: llm/final_article.py
================
import logging
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)

async def generate_final_article(
    draft: str,
    suggestions: str,
    feedback: str,
    llm_client: Any,
    prompt_handler: Any,
    user_email: str
) -> Optional[Dict[str, Any]]:
    """Generate final article incorporating editing suggestions and feedback"""
    try:
        final_prompt = await prompt_handler.format_prompt(
            'final_article',
            {
                'article_draft': draft,
                'editing_suggestions': suggestions,
                'user_feedback': feedback
            }
        )
        
        if not final_prompt:
            raise ValueError("Failed to format final article prompt")

        final_content = await llm_client.generate_response(
            system_prompt="You are an AI editor finalizing Fairness Factor blog articles...",
            user_prompt=final_prompt,
            max_tokens=2000,
            user_email=user_email
        )
        
        return {
            'success': True,
            'article': final_content
        }
    except Exception as e:
        logger.error(f"Error generating final article: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }

================
File: llm/image_description.py
================
import logging
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)

async def generate_image_description(
    article: str,
    llm_client: Any,
    prompt_handler: Any,
    user_email: str
) -> Optional[Dict[str, Any]]:
    """Generate image description based on article content"""
    try:
        image_prompt = await prompt_handler.format_prompt(
            'image_description',
            {'final_article': article}
        )
        
        if not image_prompt:
            raise ValueError("Failed to format image description prompt")

        description = await llm_client.generate_response(
            system_prompt="You are an AI designer creating image descriptions for Fairness Factor blog articles...",
            user_prompt=image_prompt,
            max_tokens=500,
            user_email=user_email
        )
        
        return {
            'success': True,
            'description': description
        }
    except Exception as e:
        logger.error(f"Error generating image description: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }

================
File: llm/llm_client.py
================
# llm/llm_client.py
import os
import anthropic
import asyncio
from dotenv import load_dotenv
import logging
from typing import Optional, List, Dict
from utils.mongo_manager import AsyncMongoManager

load_dotenv()
logger = logging.getLogger(__name__)

class AsyncLLMClient:
    def __init__(self):
        api_key = os.getenv("ANTHROPIC_API_KEY")
        if api_key is None:
            raise ValueError("ANTHROPIC_API_KEY not found in environment variables")
        self.client = anthropic.AsyncAnthropic(api_key=api_key)
        self.mongo_manager = AsyncMongoManager()

    async def log_llm_request(self, request_data: Dict) -> str:
        """Log LLM request to MongoDB"""
        _, db = await self.mongo_manager.get_connection()
        result = await db.llm_logs.insert_one({
            **request_data,
            'timestamp': datetime.now()
        })
        return str(result.inserted_id)

    async def generate_response(
        self, 
        system_prompt: str, 
        user_prompt: str, 
        max_tokens: int = 1000,
        user_email: Optional[str] = None
    ) -> Optional[str]:
        try:
            logger.info("Sending prompt to LLM...")
            
            # Log request
            request_data = {
                'system_prompt': system_prompt,
                'user_prompt': user_prompt,
                'max_tokens': max_tokens,
                'user_email': user_email
            }
            log_id = await self.log_llm_request(request_data)
            
            response = await self.client.messages.create(
                model="claude-3-opus-20240229",
                max_tokens=max_tokens,
                temperature=0.5,
                system=system_prompt,
                messages=[{
                    "role": "user",
                    "content": [{"type": "text", "text": user_prompt}]
                }]
            )
            
            result = response.content[0].text
            logger.info(f"LLM Response received for log_id: {log_id}")
            
            # Update log with response
            _, db = await self.mongo_manager.get_connection()
            await db.llm_logs.update_one(
                {'_id': log_id},
                {'$set': {'response': result, 'completed_at': datetime.now()}}
            )
            
            return result
            
        except Exception as e:
            logger.error(f"LLM error: {str(e)}")
            if log_id:
                _, db = await self.mongo_manager.get_connection()
                await db.llm_logs.update_one(
                    {'_id': log_id},
                    {'$set': {'error': str(e), 'completed_at': datetime.now()}}
                )
            return None

    async def generate_batch_responses(
        self, 
        prompts: List[Dict[str, str]], 
        user_email: Optional[str] = None
    ) -> List[Optional[str]]:
        """Generate multiple responses concurrently"""
        tasks = []
        for prompt in prompts:
            task = asyncio.create_task(
                self.generate_response(
                    prompt['system_prompt'],
                    prompt['user_prompt'],
                    prompt.get('max_tokens', 1000),
                    user_email
                )
            )
            tasks.append(task)
        
        return await asyncio.gather(*tasks)

llm_client = AsyncLLMClient()

================
File: llm/seo_generation.py
================
import logging
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)

async def generate_seo_content(
    article: str,
    image_description: str,
    llm_client: Any,
    prompt_handler: Any,
    user_email: str
) -> Optional[Dict[str, Any]]:
    """Generate SEO content for the article"""
    try:
        seo_prompt = await prompt_handler.format_prompt(
            'seo_generation',
            {
                'final_article': article,
                'image_description': image_description
            }
        )
        
        if not seo_prompt:
            raise ValueError("Failed to format SEO prompt")

        seo_content = await llm_client.generate_response(
            system_prompt="You are an SEO expert optimizing Fairness Factor blog content...",
            user_prompt=seo_prompt,
            max_tokens=1000,
            user_email=user_email
        )
        
        return {
            'success': True,
            'seo_content': seo_content
        }
    except Exception as e:
        logger.error(f"Error generating SEO content: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }

================
File: llm/topic_campaign.py
================
# llm/topic_campaign.py
import logging
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)

async def generate_topic_campaign(
    research_analysis: str,
    llm_client: Any,
    prompt_handler: Any,
    user_email: str
) -> Optional[Dict[str, Any]]:
    """Generate topic campaign based on research analysis"""
    try:
        # Format campaign prompt
        campaign_prompt = await prompt_handler.format_prompt(
            'topic_campaign',
            {'research_analysis': research_analysis}
        )
        
        if not campaign_prompt:
            raise ValueError("Failed to format campaign prompt")

        # Generate campaign content
        campaign_content = await llm_client.generate_response(
            system_prompt="You are an AI strategist creating content campaigns for Fairness Factor...",
            user_prompt=campaign_prompt,
            max_tokens=1000,
            user_email=user_email
        )
        
        return {
            'success': True,
            'campaign': campaign_content
        }
    except Exception as e:
        logger.error(f"Error generating topic campaign: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }

================
File: pages/__init__.py
================
from .topic_research import topic_research_page
from .topic_campaign import topic_campaign_page
from .article_draft import article_draft_page
from .editing_criteria import editing_criteria_page
from .final_article import final_article_page
from .image_description import image_description_page
from .seo_generation import seo_generation_page

__all__ = [
    'topic_research_page',
    'topic_campaign_page',
    'article_draft_page',
    'editing_criteria_page',
    'final_article_page',
    'image_description_page',
    'seo_generation_page'
]

================
File: pages/article_draft.py
================
# pages/article_draft.py
import streamlit as st
import asyncio
from typing import Dict, Any, Optional
from llm.llm_client import AsyncLLMClient
from utils.prompt_handler import AsyncPromptHandler
from datetime import datetime
import logging
import json

logger = logging.getLogger(__name__)

async def generate_draft(
    topic: str,
    structure: Dict[str, Any],
    research_analysis: str,
    llm_client: AsyncLLMClient,
    prompt_handler: AsyncPromptHandler,
    user_email: str
) -> Dict[str, Any]:
    """Generate article draft asynchronously"""
    try:
        # Format draft prompt
        draft_prompt = await prompt_handler.format_prompt(
            'article_draft',
            {
                'selected_topic': topic,
                'article_structure': json.dumps(structure, indent=2),
                'research_analysis': research_analysis
            }
        )
        
        if not draft_prompt:
            raise ValueError("Failed to format draft prompt")

        # Generate draft
        draft = await llm_client.generate_response(
            system_prompt=(
                "You are an AI content writer for Fairness Factor, crafting engaging "
                "blog articles about employee rights and workplace advocacy. Maintain "
                "a professional yet approachable tone, emphasizing Fairness Factor's "
                "expertise and commitment to employee advocacy."
            ),
            user_prompt=draft_prompt,
            max_tokens=2000,
            user_email=user_email
        )
        
        return {
            'success': True,
            'draft': draft
        }
    except Exception as e:
        logger.error(f"Error generating draft: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }

async def article_draft_page(
    db_handlers: Dict[str, Any],
    llm_client: AsyncLLMClient,
    prompt_handler: AsyncPromptHandler
):
    st.title("Generate Fairness Factor Blog Article Draft")
    
    user_email = st.session_state.user['email']
    
    # Check prerequisites
    if 'research_analysis' not in st.session_state:
        st.warning("⚠️ Please complete the Topic Research step first.")
        return
        
    # Display research analysis
    with st.expander("📊 Research Analysis", expanded=False):
        st.write(st.session_state['research_analysis'])
    
    # Article structure template
    default_structure = {
        "introduction": {
            "key_points": [
                "Hook the reader with a compelling opening",
                "Introduce the workplace issue or challenge",
                "Establish Fairness Factor's expertise"
            ]
        },
        "problem_statement": {
            "key_points": [
                "Define the workplace challenge",
                "Present relevant statistics or examples",
                "Explain impact on employees"
            ]
        },
        "fairness_factor_solution": {
            "key_points": [
                "Introduce Fairness Factor's approach",
                "Highlight unique value proposition",
                "Explain methodology"
            ]
        },
        "benefits": {
            "employees": [
                "Improved workplace rights",
                "Better work environment",
                "Professional growth opportunities"
            ],
            "employers": [
                "Enhanced compliance",
                "Improved employee relations",
                "Reduced legal risks"
            ]
        },
        "case_study": {
            "elements": [
                "Real-world example",
                "Challenge faced",
                "Solution implemented",
                "Results achieved"
            ]
        },
        "conclusion": {
            "elements": [
                "Summarize key points",
                "Reinforce Fairness Factor's value",
                "Call to action"
            ]
        }
    }
    
    # Article structure editor
    st.write("### 📝 Article Structure")
    col1, col2 = st.columns([2, 1])
    
    with col1:
        structure_json = st.text_area(
            "Edit article structure (JSON format):",
            value=json.dumps(default_structure, indent=2),
            height=400,
            key="article_structure"
        )
        
        try:
            article_structure = json.loads(structure_json)
        except json.JSONDecodeError:
            st.error("❌ Invalid JSON structure. Please check the format.")
            return
    
    with col2:
        st.markdown("""
        ### Structure Guidelines
        - Keep sections organized
        - Include key points
        - Maintain logical flow
        - Consider reader journey
        
        ### Tips
        - Use clear headings
        - Include examples
        - Add statistics
        - End with clear CTA
        """)
    
    # Topic input
    st.write("### 📋 Article Details")
    col1, col2 = st.columns(2)
    
    with col1:
        topic = st.text_input(
            "Article Topic:",
            key="article_topic",
            help="Enter the main topic of your article"
        )
        
    with col2:
        target_audience = st.selectbox(
            "Target Audience:",
            ["Employees", "HR Professionals", "Business Leaders", "General Public"],
            help="Select the primary audience for this article"
        )
    
    # Draft generation
    if st.button("🚀 Generate Article Draft", help="Click to generate your article draft"):
        if not topic:
            st.error("❌ Please enter an article topic.")
            return
            
        with st.spinner("✍️ Generating article draft..."):
            try:
                # Generate draft
                result = await generate_draft(
                    topic=topic,
                    structure=article_structure,
                    research_analysis=st.session_state['research_analysis'],
                    llm_client=llm_client,
                    prompt_handler=prompt_handler,
                    user_email=user_email
                )
                
                if result['success']:
                    # Save draft content
                    content_id = await db_handlers['blog'].save_article_draft(
                        user_email=user_email,
                        research_id=st.session_state['research_id'],
                        content=result['draft'],
                        metadata={
                            'topic': topic,
                            'structure': article_structure,
                            'target_audience': target_audience,
                            'generated_at': datetime.now().isoformat()
                        }
                    )
                    
                    # Update session state
                    st.session_state['article_draft'] = result['draft']
                    st.session_state['draft_id'] = content_id
                    
                    # Log activity
                    await db_handlers['analytics'].log_activity(
                        user_email=user_email,
                        activity_type='draft_generation',
                        metadata={
                            'content_id': content_id,
                            'research_id': st.session_state['research_id'],
                            'topic': topic,
                            'target_audience': target_audience
                        }
                    )
                    
                    # Display draft
                    st.success("✅ Draft generated successfully!")
                    
                    # Display draft in sections
                    st.write("### 📄 Generated Article Draft")
                    sections = result['draft'].split('\n\n')
                    for i, section in enumerate(sections):
                        with st.expander(f"Section {i+1}", expanded=i==0):
                            st.write(section)
                            
                            # Add section feedback
                            feedback = st.text_area(
                                "Section Feedback:",
                                key=f"feedback_{i}",
                                help="Add notes or feedback for this section"
                            )
                            if feedback:
                                st.session_state.setdefault('section_feedback', {})[i] = feedback
                    
                    # Draft actions
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        if st.button("📝 Edit Draft"):
                            st.session_state['editing_mode'] = True
                            
                    with col2:
                        if st.button("💾 Save Draft"):
                            try:
                                await db_handlers['blog'].update_content(
                                    content_id,
                                    {
                                        'content': result['draft'],
                                        'metadata.feedback': st.session_state.get('section_feedback', {})
                                    }
                                )
                                st.success("✅ Draft saved successfully!")
                            except Exception as e:
                                st.error(f"❌ Error saving draft: {str(e)}")
                                
                    with col3:
                        if st.button("📤 Export Draft"):
                            try:
                                export_data = {
                                    'topic': topic,
                                    'content': result['draft'],
                                    'metadata': {
                                        'generated_at': datetime.now().isoformat(),
                                        'target_audience': target_audience,
                                        'feedback': st.session_state.get('section_feedback', {})
                                    }
                                }
                                st.download_button(
                                    label="📥 Download Draft",
                                    data=json.dumps(export_data, indent=2),
                                    file_name=f"article_draft_{content_id}.json",
                                    mime="application/json"
                                )
                            except Exception as e:
                                st.error(f"❌ Error exporting draft: {str(e)}")
                    
                else:
                    st.error(f"❌ Draft generation failed: {result.get('error', 'Unknown error')}")
                    
            except Exception as e:
                st.error(f"❌ An error occurred: {str(e)}")
                logger.error(f"Error in article draft generation: {str(e)}")

    # Draft history
    with st.expander("📚 Draft History", expanded=False):
        try:
            draft_history = await db_handlers['blog'].get_user_content(
                user_email=user_email,
                content_type='draft',
                limit=5
            )
            
            if draft_history:
                for entry in draft_history:
                    col1, col2, col3 = st.columns([3, 1, 1])
                    
                    with col1:
                        st.write(f"Draft: {entry['metadata'].get('topic', 'Untitled')}")
                        st.write(f"Created: {entry['created_at'].strftime('%Y-%m-%d %H:%M')}")
                        
                    with col2:
                        if st.button("Load", key=f"load_{entry['_id']}"):
                            st.session_state['article_draft'] = entry['content']
                            st.session_state['draft_id'] = str(entry['_id'])
                            st.experimental_rerun()
                            
                    with col3:
                        if st.button("Delete", key=f"delete_{entry['_id']}"):
                            try:
                                await db_handlers['blog'].delete_content(str(entry['_id']))
                                st.success("✅ Draft deleted successfully!")
                                st.experimental_rerun()
                            except Exception as e:
                                st.error(f"❌ Error deleting draft: {str(e)}")
                    
                    st.markdown("---")
            else:
                st.info("No previous drafts found.")
                
        except Exception as e:
            st.error("Failed to load draft history")
            logger.error(f"Error loading draft history: {str(e)}")

    # Help section
    with st.expander("❓ Need Help?", expanded=False):
        st.markdown("""
        ### Writing Tips
        1. Focus on clear, concise language
        2. Use active voice
        3. Include relevant examples
        4. Back claims with data
        5. Maintain professional tone
        
        ### Common Issues
        - Writer's block? Review the research analysis
        - Structure unclear? Use the template
        - Need inspiration? Check past drafts
        
        ### Support
        Contact: content@fairnessfactor.com
        """)

if __name__ == "__main__":
    # For testing the page individually
    import os
    from dotenv import load_dotenv
    
    load_dotenv()
    
    async def test_page():
        from utils.mongo_manager import AsyncMongoManager
        from utils.prompt_handler import AsyncPromptHandler
        from llm.llm_client import AsyncLLMClient
        
        mongo_manager = AsyncMongoManager()
        client, db = await mongo_manager.get_connection()
        
        handlers = {
            'blog': None,  # Add your handlers here
            'file': None,
            'analytics': None
        }
        
        await article_draft_page(
            handlers,
            AsyncLLMClient(),
            AsyncPromptHandler(db)
        )
    
    asyncio.run(test_page())

================
File: pages/editing_criteria.py
================
# pages/editing_criteria.py
import streamlit as st
import asyncio
from typing import Dict, Any, List, Optional
from llm.llm_client import AsyncLLMClient
from utils.prompt_handler import AsyncPromptHandler
from datetime import datetime
import logging
import json

logger = logging.getLogger(__name__)

class EditingCriteria:
    """Editing criteria categories and defaults"""
    
    TONE_AND_VOICE = {
        "professional": "Maintain professional language while being approachable",
        "brand_voice": "Align with Fairness Factor's advocacy tone",
        "consistency": "Ensure consistent voice throughout the article"
    }
    
    CONTENT_QUALITY = {
        "accuracy": "Verify all facts and statistics",
        "clarity": "Ensure clear explanation of complex topics",
        "relevance": "Maintain focus on employee advocacy",
        "engagement": "Keep content engaging and reader-friendly"
    }
    
    STRUCTURE = {
        "flow": "Ensure logical progression of ideas",
        "paragraphs": "Maintain appropriate paragraph length",
        "transitions": "Use smooth transitions between sections"
    }
    
    SEO_OPTIMIZATION = {
        "keywords": "Include relevant keywords naturally",
        "readability": "Optimize for web reading",
        "headers": "Use proper header hierarchy"
    }

async def generate_editing_suggestions(
    draft: str,
    criteria: Dict[str, Dict[str, str]],
    section_feedback: Dict[int, str],
    llm_client: AsyncLLMClient,
    prompt_handler: AsyncPromptHandler,
    user_email: str
) -> Dict[str, Any]:
    """Generate editing suggestions based on criteria"""
    try:
        # Format editing prompt
        editing_prompt = await prompt_handler.format_prompt(
            'editing_criteria',
            {
                'article_draft': draft,
                'editing_criteria': json.dumps(criteria, indent=2),
                'section_feedback': json.dumps(section_feedback, indent=2)
            }
        )
        
        if not editing_prompt:
            raise ValueError("Failed to format editing prompt")

        # Generate suggestions
        suggestions = await llm_client.generate_response(
            system_prompt=(
                "You are an expert editor for Fairness Factor, providing detailed "
                "suggestions to improve blog articles. Focus on maintaining professional "
                "tone while ensuring content is engaging and aligned with Fairness "
                "Factor's mission of employee advocacy."
            ),
            user_prompt=editing_prompt,
            max_tokens=2000,
            user_email=user_email
        )
        
        return {
            'success': True,
            'suggestions': suggestions
        }
    except Exception as e:
        logger.error(f"Error generating editing suggestions: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }

async def editing_criteria_page(
    db_handlers: Dict[str, Any],
    llm_client: AsyncLLMClient,
    prompt_handler: AsyncPromptHandler
):
    st.title("Fairness Factor Blog Editing Criteria")
    
    user_email = st.session_state.user['email']
    
    # Check prerequisites
    if 'article_draft' not in st.session_state:
        st.warning("⚠️ Please generate an article draft first.")
        return
    
    # Display draft
    with st.expander("📄 Article Draft", expanded=False):
        st.write(st.session_state['article_draft'])
    
    # Editing criteria sections
    st.write("### 📝 Editing Criteria")
    
    editing_criteria = {}
    section_feedback = {}
    
    # Tabs for different criteria categories
    tabs = st.tabs([
        "Tone & Voice",
        "Content Quality",
        "Structure",
        "SEO Optimization",
        "Custom Criteria"
    ])
    
    # Tone & Voice
    with tabs[0]:
        st.markdown("#### Tone and Voice Criteria")
        editing_criteria['tone_and_voice'] = {}
        
        for key, default in EditingCriteria.TONE_AND_VOICE.items():
            value = st.text_area(
                f"{key.replace('_', ' ').title()}:",
                value=default,
                key=f"tone_{key}",
                help=f"Edit criteria for {key.replace('_', ' ')}"
            )
            editing_criteria['tone_and_voice'][key] = value
    
    # Content Quality
    with tabs[1]:
        st.markdown("#### Content Quality Criteria")
        editing_criteria['content_quality'] = {}
        
        for key, default in EditingCriteria.CONTENT_QUALITY.items():
            value = st.text_area(
                f"{key.replace('_', ' ').title()}:",
                value=default,
                key=f"quality_{key}",
                help=f"Edit criteria for {key.replace('_', ' ')}"
            )
            editing_criteria['content_quality'][key] = value
    
    # Structure
    with tabs[2]:
        st.markdown("#### Structure Criteria")
        editing_criteria['structure'] = {}
        
        for key, default in EditingCriteria.STRUCTURE.items():
            value = st.text_area(
                f"{key.replace('_', ' ').title()}:",
                value=default,
                key=f"structure_{key}",
                help=f"Edit criteria for {key.replace('_', ' ')}"
            )
            editing_criteria['structure'][key] = value
    
    # SEO Optimization
    with tabs[3]:
        st.markdown("#### SEO Optimization Criteria")
        editing_criteria['seo_optimization'] = {}
        
        for key, default in EditingCriteria.SEO_OPTIMIZATION.items():
            value = st.text_area(
                f"{key.replace('_', ' ').title()}:",
                value=default,
                key=f"seo_{key}",
                help=f"Edit criteria for {key.replace('_', ' ')}"
            )
            editing_criteria['seo_optimization'][key] = value
    
    # Custom Criteria
    with tabs[4]:
        st.markdown("#### Custom Criteria")
        custom_criteria = st.text_area(
            "Add any additional editing criteria:",
            value="",
            height=200,
            help="Enter any custom editing criteria not covered above"
        )
        if custom_criteria:
            editing_criteria['custom'] = {'additional': custom_criteria}
    
    # Section-specific feedback
    st.write("### 📑 Section-Specific Feedback")
    sections = st.session_state['article_draft'].split('\n\n')
    
    for i, section in enumerate(sections):
        with st.expander(f"Section {i+1}", expanded=False):
            st.write(section)
            feedback = st.text_area(
                "Feedback for this section:",
                key=f"section_feedback_{i}",
                help="Enter specific feedback for this section"
            )
            if feedback:
                section_feedback[i] = feedback
    
    # Generate suggestions
    if st.button("🔍 Generate Editing Suggestions", help="Click to generate editing suggestions"):
        with st.spinner("✍️ Generating editing suggestions..."):
            try:
                result = await generate_editing_suggestions(
                    draft=st.session_state['article_draft'],
                    criteria=editing_criteria,
                    section_feedback=section_feedback,
                    llm_client=llm_client,
                    prompt_handler=prompt_handler,
                    user_email=user_email
                )
                
                if result['success']:
                    # Save editing suggestions
                    content_id = await db_handlers['blog'].save_content(
                        user_email=user_email,
                        content_type='editing_suggestions',
                        content=result['suggestions'],
                        metadata={
                            'draft_id': st.session_state['draft_id'],
                            'criteria': editing_criteria,
                            'section_feedback': section_feedback,
                            'generated_at': datetime.now().isoformat()
                        }
                    )
                    
                    # Update session state
                    st.session_state['editing_suggestions'] = result['suggestions']
                    st.session_state['editing_id'] = content_id
                    
                    # Log activity
                    await db_handlers['analytics'].log_activity(
                        user_email=user_email,
                        activity_type='editing_suggestions',
                        metadata={
                            'content_id': content_id,
                            'draft_id': st.session_state['draft_id']
                        }
                    )
                    
                    # Display suggestions
                    st.success("✅ Editing suggestions generated successfully!")
                    
                    st.write("### 📋 Editing Suggestions")
                    suggestions_sections = result['suggestions'].split('\n\n')
                    
                    for i, suggestion in enumerate(suggestions_sections):
                        with st.expander(f"Suggestion {i+1}", expanded=i==0):
                            st.write(suggestion)
                            
                            # Add implementation status
                            status = st.selectbox(
                                "Implementation Status:",
                                ["Pending", "In Progress", "Implemented", "Rejected"],
                                key=f"status_{i}"
                            )
                            if status != "Pending":
                                st.session_state.setdefault('implementation_status', {})[i] = status
                    
                    # Export suggestions
                    if st.button("📤 Export Suggestions"):
                        export_data = {
                            'draft_id': st.session_state['draft_id'],
                            'suggestions': result['suggestions'],
                            'criteria': editing_criteria,
                            'section_feedback': section_feedback,
                            'implementation_status': st.session_state.get('implementation_status', {})
                        }
                        
                        st.download_button(
                            label="📥 Download Suggestions",
                            data=json.dumps(export_data, indent=2),
                            file_name=f"editing_suggestions_{content_id}.json",
                            mime="application/json"
                        )
                    
                else:
                    st.error(f"❌ Failed to generate suggestions: {result.get('error', 'Unknown error')}")
                    
            except Exception as e:
                st.error(f"❌ An error occurred: {str(e)}")
                logger.error(f"Error in editing suggestions generation: {str(e)}")
    
    # Suggestions history
    with st.expander("📚 Editing History", expanded=False):
        try:
            suggestions_history = await db_handlers['blog'].get_user_content(
                user_email=user_email,
                content_type='editing_suggestions',
                limit=5
            )
            
            if suggestions_history:
                for entry in suggestions_history:
                    col1, col2, col3 = st.columns([3, 1, 1])
                    
                    with col1:
                        st.write(f"Suggestions from {entry['created_at'].strftime('%Y-%m-%d %H:%M')}")
                        
                    with col2:
                        if st.button("Load", key=f"load_{entry['_id']}"):
                            st.session_state['editing_suggestions'] = entry['content']
                            st.session_state['editing_id'] = str(entry['_id'])
                            st.experimental_rerun()
                            
                    with col3:
                        if st.button("Delete", key=f"delete_{entry['_id']}"):
                            try:
                                await db_handlers['blog'].delete_content(str(entry['_id']))
                                st.success("✅ Suggestions deleted successfully!")
                                st.experimental_rerun()
                            except Exception as e:
                                st.error(f"❌ Error deleting suggestions: {str(e)}")
                    
                    st.markdown("---")
            else:
                st.info("No previous editing suggestions found.")
                
        except Exception as e:
            st.error("Failed to load editing history")
            logger.error(f"Error loading editing history: {str(e)}")

    # Help section
    with st.expander("❓ Need Help?", expanded=False):
        st.markdown("""
        ### Editing Guidelines
        1. Focus on clarity and consistency
        2. Ensure brand voice alignment
        3. Verify all facts and statistics
        4. Optimize for readability
        5. Maintain professional tone
        
        ### Best Practices
        - Review each section carefully
        - Consider reader perspective
        - Check for logical flow
        - Verify source citations
        
        ### Support
        Contact: editing@fairnessfactor.com
        """)

if __name__ == "__main__":
    # For testing the page individually
    import os
    from dotenv import load_dotenv
    
    load_dotenv()
    
    async def test_page():
        from utils.mongo_manager import AsyncMongoManager
        from utils.prompt_handler import AsyncPromptHandler
        from llm.llm_client import AsyncLLMClient
        
        mongo_manager = AsyncMongoManager()
        client, db = await mongo_manager.get_connection()
        
        handlers = {
            'blog': None,  # Add your handlers here
            'file': None,
            'analytics': None
        }
        
        await editing_criteria_page(
            handlers,
            AsyncLLMClient(),
            AsyncPromptHandler(db)
        )
    
    asyncio.run(test_page())

================
File: pages/final_article.py
================
# pages/final_article.py

from typing import Dict, Any, Optional, List
import streamlit as st
import asyncio
from typing import Dict, Any, Optional
from llm.llm_client import AsyncLLMClient
from utils.prompt_handler import AsyncPromptHandler
from datetime import datetime
import logging
import json
import os

logger = logging.getLogger(__name__)

class ArticleFormatter:
    """Handles article formatting and validation"""
    
    @staticmethod
    def format_metadata(
        topic: str,
        author: str,
        target_audience: str,
        keywords: List[str]
    ) -> Dict[str, Any]:
        """Format article metadata"""
        return {
            "topic": topic,
            "author": author,
            "target_audience": target_audience,
            "keywords": keywords,
            "created_at": datetime.now().isoformat(),
            "last_modified": datetime.now().isoformat()
        }
    
    @staticmethod
    def validate_article(content: str) -> bool:
        """Validate article content"""
        if not content or len(content.strip()) < 100:
            return False
        return True

async def generate_final_article(
    draft: str,
    suggestions: str,
    feedback: Dict[str, Any],
    llm_client: AsyncLLMClient,
    prompt_handler: AsyncPromptHandler,
    user_email: str
) -> Dict[str, Any]:
    """Generate final article incorporating editing suggestions and feedback"""
    try:
        final_prompt = await prompt_handler.format_prompt(
            'final_article',
            {
                'article_draft': draft,
                'editing_suggestions': suggestions,
                'user_feedback': json.dumps(feedback, indent=2)
            }
        )
        
        if not final_prompt:
            raise ValueError("Failed to format final article prompt")

        final_article = await llm_client.generate_response(
            system_prompt=(
                "You are an expert content editor finalizing a Fairness Factor blog article. "
                "Incorporate all editing suggestions while maintaining brand voice and "
                "ensuring the article effectively communicates employee advocacy messages."
            ),
            user_prompt=final_prompt,
            max_tokens=2500,
            user_email=user_email
        )
        
        if not ArticleFormatter.validate_article(final_article):
            raise ValueError("Generated article does not meet minimum requirements")
        
        return {
            'success': True,
            'article': final_article
        }
    except Exception as e:
        logger.error(f"Error generating final article: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }

async def final_article_page(
    db_handlers: Dict[str, Any],
    llm_client: AsyncLLMClient,
    prompt_handler: AsyncPromptHandler
):
    st.title("Generate Final Fairness Factor Blog Article")
    
    user_email = st.session_state.user['email']
    
    # Check prerequisites
    if 'editing_suggestions' not in st.session_state:
        st.warning("⚠️ Please complete the Editing Criteria step first.")
        return
    
    # Display previous content
    col1, col2 = st.columns(2)
    
    with col1:
        with st.expander("📄 Original Draft", expanded=False):
            st.write(st.session_state['article_draft'])
            
    with col2:
        with st.expander("✏️ Editing Suggestions", expanded=False):
            st.write(st.session_state['editing_suggestions'])
    
    # Article metadata
    st.write("### 📋 Article Details")
    
    col1, col2 = st.columns(2)
    
    with col1:
        topic = st.text_input(
            "Article Topic:",
            value=st.session_state.get('article_topic', ''),
            help="Enter the final article topic"
        )
        
        author = st.text_input(
            "Author Name:",
            value=st.session_state.get('user', {}).get('name', ''),
            help="Enter the author's name"
        )
    
    with col2:
        target_audience = st.selectbox(
            "Target Audience:",
            ["Employees", "HR Professionals", "Business Leaders", "General Public"],
            help="Select the primary audience for this article"
        )
        
        keywords = st.text_input(
            "Keywords (comma-separated):",
            help="Enter relevant keywords for SEO"
        ).split(',')
    
    # Additional feedback
    st.write("### 💭 Final Revisions")
    
    feedback = {
        "tone_adjustments": st.text_area(
            "Tone Adjustments:",
            help="Any specific adjustments to tone or voice"
        ),
        "content_focus": st.text_area(
            "Content Focus:",
            help="Areas to emphasize or clarify"
        ),
        "additional_notes": st.text_area(
            "Additional Notes:",
            help="Any other feedback for the final version"
        )
    }
    
    # Generate final article
    if st.button("🚀 Generate Final Article", help="Click to generate the final version"):
        if not all([topic, author, target_audience, keywords]):
            st.error("❌ Please fill in all article details.")
            return
            
        with st.spinner("✍️ Generating final article..."):
            try:
                result = await generate_final_article(
                    draft=st.session_state['article_draft'],
                    suggestions=st.session_state['editing_suggestions'],
                    feedback=feedback,
                    llm_client=llm_client,
                    prompt_handler=prompt_handler,
                    user_email=user_email
                )
                
                if result['success']:
                    # Prepare metadata
                    metadata = ArticleFormatter.format_metadata(
                        topic=topic,
                        author=author,
                        target_audience=target_audience,
                        keywords=keywords
                    )
                    
                    # Save final article
                    content_id = await db_handlers['blog'].save_content(
                        user_email=user_email,
                        content_type='final_article',
                        content=result['article'],
                        metadata={
                            'article_metadata': metadata,
                            'draft_id': st.session_state['draft_id'],
                            'editing_id': st.session_state['editing_id'],
                            'feedback': feedback
                        }
                    )
                    
                    # Update session state
                    st.session_state['final_article'] = result['article']
                    st.session_state['final_id'] = content_id
                    
                    # Log activity
                    await db_handlers['analytics'].log_activity(
                        user_email=user_email,
                        activity_type='final_article',
                        metadata={
                            'content_id': content_id,
                            'topic': topic
                        }
                    )
                    
                    # Display final article
                    st.success("✅ Final article generated successfully!")
                    
                    # Article preview
                    st.write("### 📖 Final Article Preview")
                    
                    # Article sections
                    sections = result['article'].split('\n\n')
                    for i, section in enumerate(sections):
                        with st.expander(f"Section {i+1}", expanded=i==0):
                            st.write(section)
                    
                    # Article actions
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        # Save as Markdown
                        if st.button("💾 Save as Markdown"):
                            try:
                                output_dir = "output/articles"
                                os.makedirs(output_dir, exist_ok=True)
                                
                                filename = f"{output_dir}/article_{content_id}.md"
                                with open(filename, "w", encoding='utf-8') as f:
                                    # Write metadata
                                    f.write("---\n")
                                    f.write(yaml.dump(metadata))
                                    f.write("---\n\n")
                                    # Write content
                                    f.write(result['article'])
                                
                                st.success(f"✅ Article saved to {filename}")
                            except Exception as e:
                                st.error(f"❌ Error saving article: {str(e)}")
                    
                    with col2:
                        # Export as JSON
                        export_data = {
                            'metadata': metadata,
                            'content': result['article'],
                            'history': {
                                'draft_id': st.session_state['draft_id'],
                                'editing_id': st.session_state['editing_id']
                            }
                        }
                        
                        st.download_button(
                            label="📤 Export as JSON",
                            data=json.dumps(export_data, indent=2),
                            file_name=f"article_{content_id}.json",
                            mime="application/json"
                        )
                    
                    with col3:
                        # Preview formatted
                        if st.button("👀 Preview Formatted"):
                            st.markdown("### " + topic)
                            st.markdown(f"*By {author}*")
                            st.markdown("---")
                            st.markdown(result['article'])
                    
                else:
                    st.error(f"❌ Failed to generate final article: {result.get('error', 'Unknown error')}")
                    
            except Exception as e:
                st.error(f"❌ An error occurred: {str(e)}")
                logger.error(f"Error in final article generation: {str(e)}")
    
    # Article history
    with st.expander("📚 Article History", expanded=False):
        try:
            article_history = await db_handlers['blog'].get_user_content(
                user_email=user_email,
                content_type='final_article',
                limit=5
            )
            
            if article_history:
                for entry in article_history:
                    col1, col2, col3 = st.columns([3, 1, 1])
                    
                    with col1:
                        metadata = entry.get('metadata', {}).get('article_metadata', {})
                        st.write(f"**{metadata.get('topic', 'Untitled')}**")
                        st.write(f"Created: {entry['created_at'].strftime('%Y-%m-%d %H:%M')}")
                        
                    with col2:
                        if st.button("Load", key=f"load_{entry['_id']}"):
                            st.session_state['final_article'] = entry['content']
                            st.session_state['final_id'] = str(entry['_id'])
                            st.experimental_rerun()
                            
                    with col3:
                        if st.button("Delete", key=f"delete_{entry['_id']}"):
                            try:
                                await db_handlers['blog'].delete_content(str(entry['_id']))
                                st.success("✅ Article deleted successfully!")
                                st.experimental_rerun()
                            except Exception as e:
                                st.error(f"❌ Error deleting article: {str(e)}")
                    
                    st.markdown("---")
            else:
                st.info("No previous articles found.")
                
        except Exception as e:
            st.error("Failed to load article history")
            logger.error(f"Error loading article history: {str(e)}")

    # Help section
    with st.expander("❓ Need Help?", expanded=False):
        st.markdown("""
        ### Final Article Guidelines
        1. Ensure all editing suggestions are addressed
        2. Maintain consistent brand voice
        3. Verify all facts and citations
        4. Check for proper formatting
        5. Review SEO optimization
        
        ### Quality Checklist
        - Clear and engaging introduction
        - Logical flow of ideas
        - Strong supporting examples
        - Effective conclusion
        - Call-to-action included
        
        ### Support
        Contact: content@fairnessfactor.com
        """)

if __name__ == "__main__":
    # For testing the page individually
    import os
    from dotenv import load_dotenv
    import yaml
    from typing import List
    
    load_dotenv()
    
    async def test_page():
        from utils.mongo_manager import AsyncMongoManager
        from utils.prompt_handler import AsyncPromptHandler
        from llm.llm_client import AsyncLLMClient
        
        mongo_manager = AsyncMongoManager()
        client, db = await mongo_manager.get_connection()
        
        handlers = {
            'blog': None,  # Add your handlers here
            'file': None,
            'analytics': None
        }
        
        await final_article_page(
            handlers,
            AsyncLLMClient(),
            AsyncPromptHandler(db)
        )
    
    asyncio.run(test_page())

================
File: pages/image_description.py
================
# pages/image_description.py
import streamlit as st
import asyncio
from typing import Dict, Any, List, Optional
from llm.llm_client import AsyncLLMClient
from utils.prompt_handler import AsyncPromptHandler
from datetime import datetime
import logging
import json
import os
from PIL import Image
import io

logger = logging.getLogger(__name__)

class ImageDescriptionGenerator:
    """Handles image description generation and validation"""
    
    STYLE_GUIDELINES = {
        "professional": "Corporate and professional style",
        "modern": "Modern and dynamic approach",
        "inclusive": "Diverse and inclusive representation",
        "empowering": "Empowering and positive imagery"
    }
    
    IMAGE_TYPES = {
        "hero": "Main header image",
        "section": "Section break image",
        "infographic": "Data visualization",
        "testimonial": "Employee testimonial image",
        "icon": "Symbolic representation"
    }
    
    @staticmethod
    def validate_description(description: str) -> bool:
        """Validate image description"""
        if not description or len(description.strip()) < 50:
            return False
        return True

async def generate_image_description(
    article: str,
    image_type: str,
    style: str,
    additional_notes: str,
    llm_client: AsyncLLMClient,
    prompt_handler: AsyncPromptHandler,
    user_email: str
) -> Dict[str, Any]:
    """Generate image description based on article content and preferences"""
    try:
        image_prompt = await prompt_handler.format_prompt(
            'image_description',
            {
                'article_content': article,
                'image_type': image_type,
                'style_preference': style,
                'additional_notes': additional_notes
            }
        )
        
        if not image_prompt:
            raise ValueError("Failed to format image description prompt")

        description = await llm_client.generate_response(
            system_prompt=(
                "You are an expert visual designer creating image descriptions for "
                "Fairness Factor blog articles. Focus on professional, inclusive, "
                "and empowering imagery that reinforces the message of employee advocacy."
            ),
            user_prompt=image_prompt,
            max_tokens=1000,
            user_email=user_email
        )
        
        if not ImageDescriptionGenerator.validate_description(description):
            raise ValueError("Generated description does not meet minimum requirements")
        
        return {
            'success': True,
            'description': description
        }
    except Exception as e:
        logger.error(f"Error generating image description: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }

async def image_description_page(
    db_handlers: Dict[str, Any],
    llm_client: AsyncLLMClient,
    prompt_handler: AsyncPromptHandler
):
    st.title("Generate Fairness Factor Blog Image Descriptions")
    
    user_email = st.session_state.user['email']
    
    # Check prerequisites
    if 'final_article' not in st.session_state:
        st.warning("⚠️ Please generate the final article first.")
        return
    
    # Display article
    with st.expander("📄 Final Article", expanded=False):
        st.write(st.session_state['final_article'])
    
    # Image description settings
    st.write("### 🎨 Image Settings")
    
    col1, col2 = st.columns(2)
    
    with col1:
        image_type = st.selectbox(
            "Image Type:",
            list(ImageDescriptionGenerator.IMAGE_TYPES.keys()),
            format_func=lambda x: ImageDescriptionGenerator.IMAGE_TYPES[x],
            help="Select the type of image needed"
        )
        
        style_preference = st.selectbox(
            "Style Preference:",
            list(ImageDescriptionGenerator.STYLE_GUIDELINES.keys()),
            format_func=lambda x: ImageDescriptionGenerator.STYLE_GUIDELINES[x],
            help="Select the preferred style"
        )
    
    with col2:
        dimensions = st.radio(
            "Image Dimensions:",
            ["16:9 (Landscape)", "1:1 (Square)", "9:16 (Portrait)"],
            help="Select the required image dimensions"
        )
        
        color_scheme = st.multiselect(
            "Color Scheme:",
            ["Fairness Factor Blue", "Professional Gray", "Accent Orange", "Neutral Tones"],
            default=["Fairness Factor Blue"],
            help="Select color preferences"
        )
    
    # Additional notes
    additional_notes = st.text_area(
        "Additional Notes:",
        help="Any specific requirements or preferences for the image"
    )
    
    # Generate description
    if st.button("🎨 Generate Image Description", help="Click to generate image description"):
        with st.spinner("✍️ Generating image description..."):
            try:
                result = await generate_image_description(
                    article=st.session_state['final_article'],
                    image_type=image_type,
                    style=style_preference,
                    additional_notes=additional_notes,
                    llm_client=llm_client,
                    prompt_handler=prompt_handler,
                    user_email=user_email
                )
                
                if result['success']:
                    # Save image description
                    content_id = await db_handlers['blog'].save_content(
                        user_email=user_email,
                        content_type='image_description',
                        content=result['description'],
                        metadata={
                            'final_id': st.session_state['final_id'],
                            'image_type': image_type,
                            'style': style_preference,
                            'dimensions': dimensions,
                            'color_scheme': color_scheme,
                            'additional_notes': additional_notes
                        }
                    )
                    
                    # Update session state
                    st.session_state['image_description'] = result['description']
                    st.session_state['image_id'] = content_id
                    
                    # Log activity
                    await db_handlers['analytics'].log_activity(
                        user_email=user_email,
                        activity_type='image_description',
                        metadata={
                            'content_id': content_id,
                            'image_type': image_type
                        }
                    )
                    
                    # Display description
                    st.success("✅ Image description generated successfully!")
                    
                    # Description display and editing
                    st.write("### 📝 Generated Description")
                    
                    edited_description = st.text_area(
                        "Edit Description:",
                        value=result['description'],
                        height=200,
                        key="edit_description"
                    )
                    
                    if edited_description != result['description']:
                        if st.button("💾 Save Edited Description"):
                            try:
                                await db_handlers['blog'].update_content(
                                    content_id,
                                    {'content': edited_description}
                                )
                                st.session_state['image_description'] = edited_description
                                st.success("✅ Description updated successfully!")
                            except Exception as e:
                                st.error(f"❌ Error saving description: {str(e)}")
                    
                    # Image specifications
                    st.write("### 📋 Image Specifications")
                    
                    specs = {
                        "Type": ImageDescriptionGenerator.IMAGE_TYPES[image_type],
                        "Style": ImageDescriptionGenerator.STYLE_GUIDELINES[style_preference],
                        "Dimensions": dimensions,
                        "Color Scheme": ", ".join(color_scheme)
                    }
                    
                    for key, value in specs.items():
                        st.write(f"**{key}:** {value}")
                    
                    # Export options
                    if st.button("📤 Export Specifications"):
                        export_data = {
                            'description': edited_description,
                            'specifications': specs,
                            'metadata': {
                                'generated_at': datetime.now().isoformat(),
                                'article_id': st.session_state['final_id']
                            }
                        }
                        
                        st.download_button(
                            label="📥 Download Specifications",
                            data=json.dumps(export_data, indent=2),
                            file_name=f"image_specs_{content_id}.json",
                            mime="application/json"
                        )
                    
                else:
                    st.error(f"❌ Failed to generate description: {result.get('error', 'Unknown error')}")
                    
            except Exception as e:
                st.error(f"❌ An error occurred: {str(e)}")
                logger.error(f"Error in image description generation: {str(e)}")
    
    # Description history
    with st.expander("📚 Description History", expanded=False):
        try:
            description_history = await db_handlers['blog'].get_user_content(
                user_email=user_email,
                content_type='image_description',
                limit=5
            )
            
            if description_history:
                for entry in description_history:
                    col1, col2, col3 = st.columns([3, 1, 1])
                    
                    with col1:
                        st.write(f"Description from {entry['created_at'].strftime('%Y-%m-%d %H:%M')}")
                        st.write(f"Type: {entry['metadata'].get('image_type', 'Unknown')}")
                        
                    with col2:
                        if st.button("Load", key=f"load_{entry['_id']}"):
                            st.session_state['image_description'] = entry['content']
                            st.session_state['image_id'] = str(entry['_id'])
                            st.experimental_rerun()
                            
                    with col3:
                        if st.button("Delete", key=f"delete_{entry['_id']}"):
                            try:
                                await db_handlers['blog'].delete_content(str(entry['_id']))
                                st.success("✅ Description deleted successfully!")
                                st.experimental_rerun()
                            except Exception as e:
                                st.error(f"❌ Error deleting description: {str(e)}")
                    
                    st.markdown("---")
            else:
                st.info("No previous descriptions found.")
                
        except Exception as e:
            st.error("Failed to load description history")
            logger.error(f"Error loading description history: {str(e)}")

    # Help section
    with st.expander("❓ Need Help?", expanded=False):
        st.markdown("""
        ### Image Description Guidelines
        1. Be specific and detailed
        2. Consider brand alignment
        3. Focus on inclusivity
        4. Maintain professional tone
        5. Include technical requirements
        
        ### Best Practices
        - Use clear, descriptive language
        - Include composition details
        - Specify lighting and mood
        - Consider cultural sensitivity
        - Include technical specifications
        
        ### Support
        Contact: design@fairnessfactor.com
        """)

if __name__ == "__main__":
    # For testing the page individually
    import os
    from dotenv import load_dotenv
    
    load_dotenv()
    
    async def test_page():
        from utils.mongo_manager import AsyncMongoManager
        from utils.prompt_handler import AsyncPromptHandler
        from llm.llm_client import AsyncLLMClient
        
        mongo_manager = AsyncMongoManager()
        client, db = await mongo_manager.get_connection()
        
        handlers = {
            'blog': None,  # Add your handlers here
            'file': None,
            'analytics': None
        }
        
        await image_description_page(
            handlers,
            AsyncLLMClient(),
            AsyncPromptHandler(db)
        )
    
    asyncio.run(test_page())

================
File: pages/seo_generation.py
================
# pages/seo_generation.py
import streamlit as st
import asyncio
from typing import Dict, Any, List, Optional
from llm.llm_client import AsyncLLMClient
from utils.prompt_handler import AsyncPromptHandler
from datetime import datetime
import logging
import json
import re

logger = logging.getLogger(__name__)

class SEOGenerator:
    """Handles SEO content generation and validation"""
    
    META_REQUIREMENTS = {
        "title": {
            "min_length": 30,
            "max_length": 60,
            "required_elements": ["brand", "keyword"]
        },
        "description": {
            "min_length": 120,
            "max_length": 160,
            "required_elements": ["value proposition", "call to action"]
        }
    }
    
    KEYWORD_TYPES = {
        "primary": "Main focus keyword",
        "secondary": "Supporting keywords",
        "long_tail": "Long-tail variations",
        "related": "Related terms"
    }
    
    @staticmethod
    def validate_meta_title(title: str) -> Dict[str, Any]:
        """Validate meta title"""
        length = len(title)
        return {
            'valid': 30 <= length <= 60,
            'length': length,
            'message': f"Title length: {length}/60 characters"
        }
    
    @staticmethod
    def validate_meta_description(description: str) -> Dict[str, Any]:
        """Validate meta description"""
        length = len(description)
        return {
            'valid': 120 <= length <= 160,
            'length': length,
            'message': f"Description length: {length}/160 characters"
        }
    
    @staticmethod
    def generate_slug(title: str) -> str:
        """Generate URL slug from title"""
        # Convert to lowercase and replace spaces with hyphens
        slug = title.lower().strip()
        # Remove special characters
        slug = re.sub(r'[^\w\s-]', '', slug)
        # Replace spaces with hyphens
        slug = re.sub(r'[-\s]+', '-', slug)
        return slug

async def generate_seo_content(
    article: str,
    image_description: str,
    target_keywords: List[str],
    llm_client: AsyncLLMClient,
    prompt_handler: AsyncPromptHandler,
    user_email: str
) -> Dict[str, Any]:
    """Generate SEO content based on article and keywords"""
    try:
        seo_prompt = await prompt_handler.format_prompt(
            'seo_generation',
            {
                'article_content': article,
                'image_description': image_description,
                'target_keywords': ', '.join(target_keywords)
            }
        )
        
        if not seo_prompt:
            raise ValueError("Failed to format SEO prompt")

        seo_content = await llm_client.generate_response(
            system_prompt=(
                "You are an SEO expert optimizing content for Fairness Factor's blog. "
                "Focus on employee advocacy keywords while maintaining natural language "
                "and providing comprehensive meta information for optimal search visibility."
            ),
            user_prompt=seo_prompt,
            max_tokens=1000,
            user_email=user_email
        )
        
        # Parse SEO content into structured format
        try:
            seo_data = json.loads(seo_content)
        except json.JSONDecodeError:
            raise ValueError("Generated SEO content is not in valid JSON format")
        
        return {
            'success': True,
            'seo_data': seo_data
        }
    except Exception as e:
        logger.error(f"Error generating SEO content: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }

async def seo_generation_page(
    db_handlers: Dict[str, Any],
    llm_client: AsyncLLMClient,
    prompt_handler: AsyncPromptHandler
):
    st.title("Generate SEO Content for Fairness Factor Blog")
    
    user_email = st.session_state.user['email']
    
    # Check prerequisites
    if 'final_article' not in st.session_state or 'image_description' not in st.session_state:
        st.warning("⚠️ Please complete the Final Article and Image Description steps first.")
        return
    
    # Display previous content
    with st.expander("📄 Article Content", expanded=False):
        st.write(st.session_state['final_article'])
        st.write("### Image Description")
        st.write(st.session_state['image_description'])
    
    # SEO Settings
    st.write("### 🎯 SEO Target Settings")
    
    col1, col2 = st.columns(2)
    
    with col1:
        primary_keyword = st.text_input(
            "Primary Keyword:",
            help="Enter the main keyword to target"
        )
        
        secondary_keywords = st.text_area(
            "Secondary Keywords (one per line):",
            help="Enter supporting keywords"
        ).split('\n')
    
    with col2:
        target_location = st.selectbox(
            "Target Location:",
            ["Global", "United States", "Europe", "Asia"],
            help="Select primary geographic target"
        )
        
        target_devices = st.multiselect(
            "Target Devices:",
            ["Desktop", "Mobile", "Tablet"],
            default=["Desktop", "Mobile"],
            help="Select target devices"
        )
    
    # Advanced SEO Settings
    with st.expander("⚙️ Advanced SEO Settings", expanded=False):
        search_intent = st.selectbox(
            "Search Intent:",
            ["Informational", "Navigational", "Commercial", "Transactional"],
            help="Select primary search intent"
        )
        
        content_type = st.selectbox(
            "Content Type:",
            ["Blog Post", "Article", "Guide", "Case Study"],
            help="Select content type for schema markup"
        )
        
        competition_level = st.slider(
            "Competition Level:",
            min_value=1,
            max_value=10,
            value=5,
            help="Estimate keyword competition level"
        )
    
    # Generate SEO content
    if st.button("🚀 Generate SEO Content", help="Click to generate SEO optimization content"):
        if not primary_keyword:
            st.error("❌ Please enter a primary keyword.")
            return
            
        with st.spinner("✍️ Generating SEO content..."):
            try:
                result = await generate_seo_content(
                    article=st.session_state['final_article'],
                    image_description=st.session_state['image_description'],
                    target_keywords=[primary_keyword] + secondary_keywords,
                    llm_client=llm_client,
                    prompt_handler=prompt_handler,
                    user_email=user_email
                )
                
                if result['success']:
                    seo_data = result['seo_data']
                    
                    # Save SEO content
                    content_id = await db_handlers['blog'].save_content(
                        user_email=user_email,
                        content_type='seo_content',
                        content=json.dumps(seo_data),
                        metadata={
                            'final_id': st.session_state['final_id'],
                            'primary_keyword': primary_keyword,
                            'secondary_keywords': secondary_keywords,
                            'target_location': target_location,
                            'target_devices': target_devices,
                            'search_intent': search_intent,
                            'content_type': content_type,
                            'competition_level': competition_level
                        }
                    )
                    
                    # Update session state
                    st.session_state['seo_content'] = seo_data
                    st.session_state['seo_id'] = content_id
                    
                    # Log activity
                    await db_handlers['analytics'].log_activity(
                        user_email=user_email,
                        activity_type='seo_generation',
                        metadata={
                            'content_id': content_id,
                            'primary_keyword': primary_keyword
                        }
                    )
                    
                    # Display SEO content
                    st.success("✅ SEO content generated successfully!")
                    
                    # Meta Information
                    st.write("### 📊 Meta Information")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        meta_title = st.text_input(
                            "Meta Title:",
                            value=seo_data.get('meta_title', ''),
                            help="Edit meta title"
                        )
                        
                        title_validation = SEOGenerator.validate_meta_title(meta_title)
                        st.write(title_validation['message'])
                        if not title_validation['valid']:
                            st.warning("⚠️ Title length should be between 30-60 characters")
                    
                    with col2:
                        meta_description = st.text_area(
                            "Meta Description:",
                            value=seo_data.get('meta_description', ''),
                            help="Edit meta description"
                        )
                        
                        desc_validation = SEOGenerator.validate_meta_description(meta_description)
                        st.write(desc_validation['message'])
                        if not desc_validation['valid']:
                            st.warning("⚠️ Description length should be between 120-160 characters")
                    
                    # URL Slug
                    suggested_slug = SEOGenerator.generate_slug(meta_title)
                    url_slug = st.text_input(
                        "URL Slug:",
                        value=suggested_slug,
                        help="Edit URL slug"
                    )
                    
                    # Keyword Analysis
                    st.write("### 🔍 Keyword Analysis")
                    
                    keyword_data = seo_data.get('keyword_analysis', {})
                    for keyword_type, keywords in keyword_data.items():
                        with st.expander(f"{keyword_type.title()} Keywords"):
                            edited_keywords = st.text_area(
                                f"Edit {keyword_type} keywords:",
                                value='\n'.join(keywords),
                                key=f"edit_{keyword_type}"
                            ).split('\n')
                            keyword_data[keyword_type] = edited_keywords
                    
                    # Schema Markup
                    st.write("### 📝 Schema Markup")
                    schema_markup = seo_data.get('schema_markup', {})
                    schema_json = st.text_area(
                        "Edit Schema Markup:",
                        value=json.dumps(schema_markup, indent=2),
                        height=200
                    )
                    
                    # Save changes
                    if st.button("💾 Save SEO Changes"):
                        try:
                            updated_seo_data = {
                                'meta_title': meta_title,
                                'meta_description': meta_description,
                                'url_slug': url_slug,
                                'keyword_analysis': keyword_data,
                                'schema_markup': json.loads(schema_json)
                            }
                            
                            await db_handlers['blog'].update_content(
                                content_id,
                                {'content': json.dumps(updated_seo_data)}
                            )
                            
                            st.session_state['seo_content'] = updated_seo_data
                            st.success("✅ SEO content updated successfully!")
                            
                        except Exception as e:
                            st.error(f"❌ Error saving SEO content: {str(e)}")
                    
                    # Export options
                    if st.button("📤 Export SEO Package"):
                        export_data = {
                            'meta_information': {
                                'title': meta_title,
                                'description': meta_description,
                                'url_slug': url_slug
                            },
                            'keyword_analysis': keyword_data,
                            'schema_markup': json.loads(schema_json),
                            'settings': {
                                'target_location': target_location,
                                'target_devices': target_devices,
                                'search_intent': search_intent,
                                'content_type': content_type,
                                'competition_level': competition_level
                            }
                        }
                        
                        st.download_button(
                            label="📥 Download SEO Package",
                            data=json.dumps(export_data, indent=2),
                            file_name=f"seo_package_{content_id}.json",
                            mime="application/json"
                        )
                    
                else:
                    st.error(f"❌ Failed to generate SEO content: {result.get('error', 'Unknown error')}")
                    
            except Exception as e:
                st.error(f"❌ An error occurred: {str(e)}")
                logger.error(f"Error in SEO content generation: {str(e)}")
    
    # SEO History
    with st.expander("📚 SEO History", expanded=False):
        try:
            seo_history = await db_handlers['blog'].get_user_content(
                user_email=user_email,
                content_type='seo_content',
                limit=5
            )
            
            if seo_history:
                for entry in seo_history:
                    col1, col2, col3 = st.columns([3, 1, 1])
                    
                    with col1:
                        metadata = entry.get('metadata', {})
                        st.write(f"**Primary Keyword:** {metadata.get('primary_keyword', 'Unknown')}")
                        st.write(f"Generated: {entry['created_at'].strftime('%Y-%m-%d %H:%M')}")
                        
                    with col2:
                        if st.button("Load", key=f"load_{entry['_id']}"):
                            st.session_state['seo_content'] = json.loads(entry['content'])
                            st.session_state['seo_id'] = str(entry['_id'])
                            st.experimental_rerun()
                            
                    with col3:
                        if st.button("Delete", key=f"delete_{entry['_id']}"):
                            try:
                                await db_handlers['blog'].delete_content(str(entry['_id']))
                                st.success("✅ SEO content deleted successfully!")
                                st.experimental_rerun()
                            except Exception as e:
                                st.error(f"❌ Error deleting SEO content: {str(e)}")
                    
                    st.markdown("---")
            else:
                st.info("No previous SEO content found.")
                
        except Exception as e:
            st.error("Failed to load SEO history")
            logger.error(f"Error loading SEO history: {str(e)}")

    # Help section
    with st.expander("❓ Need Help?", expanded=False):
        st.markdown("""
        ### SEO Guidelines
        1. Use target keywords naturally
        2. Optimize meta information
        3. Create descriptive URLs
        4. Implement proper schema markup
        5. Consider search intent
        
        ### Best Practices
        - Keep titles under 60 characters
        - Meta descriptions between 120-160 characters
        - Use relevant keywords
        - Include call-to-action
        - Optimize for mobile
        
        ### Support
        Contact: seo@fairnessfactor.com
        """)

if __name__ == "__main__":
    # For testing the page individually
    import os
    from dotenv import load_dotenv
    
    load_dotenv()
    
    async def test_page():
        from utils.mongo_manager import AsyncMongoManager
        from utils.prompt_handler import AsyncPromptHandler
        from llm.llm_client import AsyncLLMClient
        
        mongo_manager = AsyncMongoManager()
        client, db = await mongo_manager.get_connection()
        
        handlers = {
            'blog': None,  # Add your handlers here
            'file': None,
            'analytics': None
        }
        
        await seo_generation_page(
            handlers,
            AsyncLLMClient(),
            AsyncPromptHandler(db)
        )
    
    asyncio.run(test_page())

================
File: pages/topic_campaign.py
================
# pages/topic_campaign.py
import streamlit as st
import asyncio
from typing import Dict, Any
from llm.llm_client import AsyncLLMClient
from utils.prompt_handler import AsyncPromptHandler
import logging

logger = logging.getLogger(__name__)

async def generate_campaign(
    research_analysis: str,
    llm_client: AsyncLLMClient,
    prompt_handler: AsyncPromptHandler,
    user_email: str
) -> Dict[str, Any]:
    """Generate topic campaign asynchronously"""
    try:
        # Format campaign prompt
        campaign_prompt = await prompt_handler.format_prompt(
            'topic_campaign',
            {'research_analysis': research_analysis}
        )
        
        if not campaign_prompt:
            raise ValueError("Failed to format campaign prompt")

        # Generate campaign
        campaign = await llm_client.generate_response(
            system_prompt="You are an AI strategist creating content campaigns for Fairness Factor...",
            user_prompt=campaign_prompt,
            max_tokens=1500,
            user_email=user_email
        )
        
        return {
            'success': True,
            'campaign': campaign
        }
    except Exception as e:
        logger.error(f"Error generating campaign: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }

async def topic_campaign_page(
    db_handlers: Dict[str, Any],
    llm_client: AsyncLLMClient,
    prompt_handler: AsyncPromptHandler
):
    st.title("Generate Fair Fight Topic Campaign")
    
    user_email = st.session_state.user['email']
    
    if 'research_analysis' not in st.session_state:
        st.warning("Please complete the Topic Research step first.")
        return
    
    st.write("Research Analysis:")
    st.write(st.session_state['research_analysis'])
    
    # Allow viewing and editing the campaign prompt
    try:
        campaign_prompt = await prompt_handler.load_prompt('topic_campaign')
        edited_prompt = st.text_area(
            "Edit campaign prompt if needed:",
            value=campaign_prompt,
            height=200,
            key="campaign_prompt"
        )
        
        if edited_prompt != campaign_prompt:
            if st.button("Save Prompt"):
                try:
                    await prompt_handler.save_prompt(
                        'topic_campaign',
                        edited_prompt,
                        user_email
                    )
                    st.success("Campaign prompt saved successfully!")
                except Exception as e:
                    st.error(f"Error saving prompt: {str(e)}")
    except Exception as e:
        st.error(f"Error loading prompt: {str(e)}")
    
    if st.button("Generate Topic Campaign"):
        with st.spinner("Generating topic campaign..."):
            try:
                result = await generate_campaign(
                    research_analysis=st.session_state['research_analysis'],
                    llm_client=llm_client,
                    prompt_handler=prompt_handler,
                    user_email=user_email
                )
                
                if result['success']:
                    # Save campaign content
                    content_id = await db_handlers['blog'].save_content(
                        user_email=user_email,
                        content_type='campaign',
                        content=result['campaign'],
                        metadata={'research_id': st.session_state['research_id']}
                    )
                    
                    # Update session state
                    st.session_state['topic_campaign'] = result['campaign']
                    st.session_state['campaign_id'] = content_id
                    
                    # Log activity
                    await db_handlers['analytics'].log_activity(
                        user_email=user_email,
                        activity_type='campaign_generation',
                        metadata={'content_id': content_id}
                    )
                    
                    # Display campaign
                    st.write("Generated Topic Campaign:")
                    st.write(result['campaign'])
                    
                    # Topic selection
                    campaign_topics = result['campaign'].split('\n')
                    selected_topic = st.selectbox(
                        "Select a topic for the Fair Fight blog article:",
                        campaign_topics
                    )
                    
                    if selected_topic:
                        st.session_state['selected_topic'] = selected_topic
                        
                else:
                    st.error(f"Campaign generation failed: {result.get('error', 'Unknown error')}")
                    
            except Exception as e:
                st.error(f"An error occurred: {str(e)}")
                logger.error(f"Error in topic campaign generation: {str(e)}")

    # Display campaign history
    with st.expander("View Campaign History"):
        try:
            campaign_history = await db_handlers['blog'].get_user_content(
                user_email=user_email,
                content_type='campaign',
                limit=5
            )
            
            if campaign_history:
                for entry in campaign_history:
                    st.write(f"Campaign from {entry['created_at'].strftime('%Y-%m-%d %H:%M')}")
                    if st.button(f"Load Campaign {entry['_id']}", key=f"load_{entry['_id']}"):
                        st.session_state['topic_campaign'] = entry['content']
                        st.session_state['campaign_id'] = str(entry['_id'])
                        st.experimental_rerun()
            else:
                st.info("No previous campaigns found.")
                
        except Exception as e:
            st.error("Failed to load campaign history")
            logger.error(f"Error loading campaign history: {str(e)}")

================
File: pages/topic_research.py
================
# pages/topic_research.py
import streamlit as st
import asyncio
from typing import List, Dict, Any, Optional
import PyPDF2
import docx2txt
from llm.llm_client import AsyncLLMClient
from utils.prompt_handler import AsyncPromptHandler
import logging
import io
from datetime import datetime

logger = logging.getLogger(__name__)

async def process_pdf(file_data: bytes) -> Optional[str]:
    """Process PDF file and extract text content"""
    try:
        pdf_file = io.BytesIO(file_data)
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        content = []
        
        for page in pdf_reader.pages:
            content.append(page.extract_text())
            
        return "\n".join(content)
    except Exception as e:
        logger.error(f"Error processing PDF: {str(e)}")
        return None

async def process_docx(file_data: bytes) -> Optional[str]:
    """Process DOCX file and extract text content"""
    try:
        return docx2txt.process(io.BytesIO(file_data))
    except Exception as e:
        logger.error(f"Error processing DOCX: {str(e)}")
        return None

async def process_text_file(file_data: bytes) -> Optional[str]:
    """Process text file and extract content"""
    try:
        return file_data.decode('utf-8')
    except Exception as e:
        logger.error(f"Error processing text file: {str(e)}")
        return None

async def process_file(
    uploaded_file: Any,
    file_handlers: Dict[str, Any]
) -> Optional[Dict[str, Any]]:
    """Process uploaded file based on type"""
    try:
        file_data = uploaded_file.getvalue()
        content = None
        
        if uploaded_file.type == "application/pdf":
            content = await process_pdf(file_data)
        elif uploaded_file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
            content = await process_docx(file_data)
        else:  # For .txt and .md files
            content = await process_text_file(file_data)
            
        if content is None:
            raise ValueError(f"Failed to process file: {uploaded_file.name}")
            
        return {
            'filename': uploaded_file.name,
            'content': content,
            'file_type': uploaded_file.type
        }
    except Exception as e:
        logger.error(f"Error processing file {uploaded_file.name}: {str(e)}")
        return None

async def analyze_documents(
    documents: List[Dict[str, Any]],
    llm_client: AsyncLLMClient,
    prompt_handler: AsyncPromptHandler,
    user_email: str
) -> Dict[str, Any]:
    """Analyze document contents using LLM"""
    try:
        # Prepare documents for analysis
        doc_contents = [doc['content'] for doc in documents]
        doc_summary = "\n\n".join([
            f"Document: {doc['filename']}\nContent:\n{doc['content']}"
            for doc in documents
        ])
        
        # Format research prompt
        research_prompt = await prompt_handler.format_prompt(
            'topic_research',
            {
                'documents': doc_summary,
                'num_documents': len(documents)
            }
        )
        
        if not research_prompt:
            raise ValueError("Failed to format research prompt")

        # Generate analysis
        analysis = await llm_client.generate_response(
            system_prompt=(
                "You are an AI research assistant analyzing documents for "
                "Fairness Factor blog content. Focus on employee rights, "
                "workplace issues, and legal advocacy themes."
            ),
            user_prompt=research_prompt,
            max_tokens=2000,
            user_email=user_email
        )
        
        return {
            'success': True,
            'analysis': analysis,
            'document_contents': doc_contents
        }
    except Exception as e:
        logger.error(f"Error analyzing documents: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }

async def topic_research_page(
    db_handlers: Dict[str, Any],
    llm_client: AsyncLLMClient,
    prompt_handler: AsyncPromptHandler
):
    st.title("Fairness Factor Blog Topic Research")
    
    user_email = st.session_state.user['email']
    
    # Display research guidelines
    with st.expander("Research Guidelines", expanded=True):
        st.markdown("""
        ### Document Upload Guidelines
        - Upload up to 3 research documents
        - Supported formats: PDF, DOCX, TXT, MD
        - Focus on employee rights, workplace issues, and legal advocacy
        - Documents should be relevant to Fairness Factor's mission
        
        ### Best Practices
        1. Include diverse perspectives
        2. Use recent and reliable sources
        3. Consider industry trends
        4. Focus on actionable insights
        """)
    
    # File upload section
    st.write("### Upload Research Documents")
    uploaded_files = st.file_uploader(
        "Upload up to 3 documents",
        type=["pdf", "docx", "txt", "md"],
        accept_multiple_files=True,
        key="research_files"
    )
    
    if uploaded_files:
        if len(uploaded_files) > 3:
            st.warning("⚠️ Please upload a maximum of 3 documents.")
            return

        processed_documents = []
        file_metadata = []
        
        # Process uploaded files
        with st.spinner("Processing documents..."):
            for uploaded_file in uploaded_files:
                try:
                    # Process file
                    processed_file = await process_file(uploaded_file, db_handlers)
                    if processed_file:
                        processed_documents.append(processed_file)
                        
                        # Save to GridFS
                        file_id = await db_handlers['file'].save_file(
                            filename=uploaded_file.name,
                            file_data=uploaded_file.getvalue(),
                            metadata={
                                'user_email': user_email,
                                'file_type': uploaded_file.type,
                                'content_type': 'research_document',
                                'upload_date': datetime.now().isoformat()
                            }
                        )
                        
                        file_metadata.append({
                            'file_id': file_id,
                            'filename': uploaded_file.name,
                            'file_type': uploaded_file.type
                        })
                        
                except Exception as e:
                    st.error(f"Error processing {uploaded_file.name}: {str(e)}")
                    continue
        
        # Display processed files
        if processed_documents:
            st.write("### Processed Documents")
            for doc in processed_documents:
                with st.expander(f"📄 {doc['filename']}", expanded=False):
                    st.text_area(
                        "Content Preview",
                        value=doc['content'][:500] + "...",
                        height=150,
                        key=f"preview_{doc['filename']}"
                    )
            
            # Analyze documents button
            if st.button("🔍 Analyze Documents"):
                with st.spinner("Analyzing documents..."):
                    try:
                        # Analyze documents
                        result = await analyze_documents(
                            processed_documents,
                            llm_client,
                            prompt_handler,
                            user_email
                        )
                        
                        if result['success']:
                            # Save research content
                            content_id = await db_handlers['blog'].save_research(
                                user_email=user_email,
                                document_contents=result['document_contents'],
                                analysis=result['analysis'],
                                metadata={
                                    'files': file_metadata,
                                    'analysis_date': datetime.now().isoformat()
                                }
                            )
                            
                            # Update session state
                            st.session_state['research_analysis'] = result['analysis']
                            st.session_state['research_id'] = content_id
                            st.session_state['research_files'] = file_metadata
                            
                            # Log activity
                            await db_handlers['analytics'].log_activity(
                                user_email=user_email,
                                activity_type='research_analysis',
                                metadata={
                                    'content_id': content_id,
                                    'num_documents': len(processed_documents),
                                    'files': file_metadata
                                }
                            )
                            
                            # Display results
                            st.success("✅ Analysis completed successfully!")
                            st.write("### Research Analysis")
                            
                            # Display analysis in sections
                            analysis_sections = result['analysis'].split('\n\n')
                            for i, section in enumerate(analysis_sections):
                                with st.expander(f"Section {i+1}", expanded=i==0):
                                    st.write(section)
                            
                            # Add to research history
                            if 'research_history' not in st.session_state:
                                st.session_state.research_history = []
                            st.session_state.research_history.append({
                                'id': content_id,
                                'date': datetime.now(),
                                'analysis': result['analysis']
                            })
                            
                        else:
                            st.error(f"❌ Analysis failed: {result.get('error', 'Unknown error')}")
                            
                    except Exception as e:
                        st.error(f"❌ An error occurred: {str(e)}")
                        logger.error(f"Error in topic research: {str(e)}")

    # Research history section
    with st.expander("📚 View Research History", expanded=False):
        try:
            research_history = await db_handlers['blog'].get_user_content(
                user_email=user_email,
                content_type='research',
                limit=5
            )
            
            if research_history:
                for entry in research_history:
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write(f"Research from {entry['created_at'].strftime('%Y-%m-%d %H:%M')}")
                    with col2:
                        if st.button(
                            "Load",
                            key=f"load_{entry['_id']}",
                            help="Load this research analysis"
                        ):
                            st.session_state['research_analysis'] = entry['analysis']
                            st.session_state['research_id'] = str(entry['_id'])
                            st.experimental_rerun()
                    st.markdown("---")
            else:
                st.info("No previous research found.")
                
        except Exception as e:
            st.error("Failed to load research history")
            logger.error(f"Error loading research history: {str(e)}")

    # Help section
    with st.expander("❓ Need Help?", expanded=False):
        st.markdown("""
        ### Troubleshooting
        - Make sure your documents are in supported formats
        - Check that files are not corrupted
        - Ensure documents are relevant to the topic
        
        ### Contact Support
        If you continue experiencing issues, contact support at:
        support@fairnessfactor.com
        """)

if __name__ == "__main__":
    # For testing the page individually
    import os
    from dotenv import load_dotenv
    
    load_dotenv()
    
    async def test_page():
        from utils.mongo_manager import AsyncMongoManager
        from utils.prompt_handler import AsyncPromptHandler
        from llm.llm_client import AsyncLLMClient
        
        mongo_manager = AsyncMongoManager()
        client, db = await mongo_manager.get_connection()
        
        handlers = {
            'blog': None,  # Add your handlers here
            'file': None,
            'analytics': None
        }
        
        await topic_research_page(
            handlers,
            AsyncLLMClient(),
            AsyncPromptHandler(db)
        )
    
    asyncio.run(test_page())

================
File: Procfile
================
# Procfile
web: streamlit run app.py

================
File: prompts/article_draft.txt
================
Create a comprehensive blog article draft based on:

Topic: {selected_topic}

Article Structure:
{article_structure}

Research Analysis:
{research_analysis}

Guidelines:
1. Maintain professional yet approachable tone
2. Include relevant statistics and examples
3. Highlight Fairness Factor's expertise
4. Address common employee concerns
5. Provide actionable insights
6. Include expert perspectives
7. Reference legal considerations
8. End with clear call-to-action

Key Elements:
- Engaging introduction
- Clear problem statement
- Fairness Factor's unique approach
- Benefits for employees and employers
- Real-world examples
- Practical solutions
- Expert insights
- Conclusion with next steps

Ensure content demonstrates Fairness Factor's commitment to employee advocacy while maintaining readability and engagement.

================
File: prompts/editing_criteria.txt
================
Review and provide editing suggestions for the following article:

Article Draft:
{article_draft}

Editing Criteria:
{editing_criteria}

Section-Specific Feedback:
{section_feedback}

Provide detailed suggestions for:
1. Content Enhancement
   - Clarity and coherence
   - Supporting evidence
   - Example effectiveness
   - Argument strength

2. Style Improvements
   - Tone consistency
   - Brand voice alignment
   - Language accessibility
   - Professional polish

3. Structure Optimization
   - Flow and transitions
   - Section balance
   - Information hierarchy
   - Logical progression

4. Engagement Elements
   - Reader engagement
   - Call-to-action effectiveness
   - Value proposition clarity
   - Emotional connection

Format suggestions with specific examples and recommended changes for each section.

================
File: prompts/final_article.txt
================
Generate the final version of the article incorporating:

Original Draft:
{article_draft}

Editing Suggestions:
{editing_suggestions}

Additional Feedback:
{user_feedback}

Focus on:
1. Implementing all approved edits
2. Maintaining consistent voice
3. Enhancing readability
4. Strengthening arguments
5. Polishing transitions
6. Optimizing structure
7. Reinforcing key messages
8. Perfecting call-to-action

Ensure the final article:
- Demonstrates expertise
- Engages target audience
- Provides clear value
- Maintains professional tone
- Reflects brand voice
- Drives desired action
- Supports SEO goals

================
File: prompts/image_description.txt
================
Generate image descriptions based on:

Article Content:
{article_content}

Image Type:
{image_type}

Style Preference:
{style_preference}

Additional Notes:
{additional_notes}

Provide detailed descriptions including:
1. Visual Elements
   - Composition
   - Color scheme
   - Lighting
   - Focal points

2. Subject Matter
   - Main elements
   - People representation
   - Setting/environment
   - Props/objects

3. Emotional Impact
   - Mood/atmosphere
   - Brand alignment
   - Message reinforcement
   - Viewer connection

4. Technical Specifications
   - Dimensions
   - Resolution
   - Format requirements
   - Usage considerations

Ensure descriptions align with Fairness Factor's professional image while supporting the article's message.

================
File: prompts/seo_generation.txt
================
Generate SEO optimization content for:

Article Content:
{article_content}

Image Description:
{image_description}

Target Keywords:
{target_keywords}

Provide comprehensive SEO elements:
1. Meta Information
   - Title (50-60 characters)
   - Description (150-160 characters)
   - URL slug
   - Canonical URL

2. Keyword Analysis
   - Primary keyword placement
   - Secondary keywords
   - Long-tail variations
   - LSI keywords

3. Content Optimization
   - Heading hierarchy
   - Keyword density
   - Internal linking
   - External linking

4. Schema Markup
   - Article schema
   - Organization schema
   - Author schema
   - FAQ schema (if applicable)

5. Technical SEO
   - Mobile optimization
   - Page speed considerations
   - Image alt text
   - Meta robots tags

Format response as JSON with clear sections for each element.

================
File: prompts/topic_campaign.txt
================
Based on the following research analysis:

{research_analysis}

Generate a strategic content campaign that:
1. Identifies 5-7 compelling blog topics
2. Prioritizes topics by relevance and impact
3. Suggests angles for each topic
4. Identifies target audience segments
5. Outlines potential calls-to-action

For each topic, include:
- Working title
- Key message
- Target audience
- Main pain points addressed
- Unique value proposition
- Supporting data points
- Potential expert quotes/insights
- Call-to-action suggestions

Ensure all topics align with Fairness Factor's mission of employee advocacy and workplace fairness.

================
File: prompts/topic_research.txt
================
You are analyzing research documents for Fairness Factor's blog content.

Research Documents:
{documents}

Please provide a comprehensive analysis focusing on:
1. Key themes and patterns
2. Employee advocacy opportunities
3. Workplace challenges identified
4. Potential solutions and approaches
5. Relevant statistics and data points
6. Industry trends
7. Legal considerations
8. Employee impact stories

Format your analysis with clear sections and highlight actionable insights that align with Fairness Factor's mission of employee advocacy.

Consider:
- Current workplace issues
- Employee rights and protections
- Legal precedents and regulations
- Industry best practices
- Success stories and case studies

Your analysis should help inform compelling blog content that demonstrates Fairness Factor's expertise in employee advocacy.

================
File: README.md
================
# README.md
# Fairness Factor Blog Generator

## Overview
A professional blog content generation tool built for Fairness Factor, featuring secure authentication, MongoDB integration, and automated content workflows.

## Features
- Secure authentication with domain restriction
- Content generation workflows
- MongoDB integration for data persistence
- File upload and processing
- SEO optimization tools
- User management system

## Setup
1. Clone the repository:
```bash
git clone https://github.com/yourusername/fairness-factor-blog-generator.git
cd fairness-factor-blog-generator
```

2. Create and activate virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\\Scripts\\activate   # Windows
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Set up environment variables:
```bash
cp .env.example .env
# Edit .env with your configuration
```

5. Initialize MongoDB:
```bash
python setup_mongodb.py
```

6. Run the application:
```bash
streamlit run app.py
```

## Environment Variables
Create a `.env` file with:
```
MONGODB_URI=your_mongodb_uri
JWT_SECRET_KEY=your_jwt_secret
ANTHROPIC_API_KEY=your_anthropic_api_key
```

## Contributing
1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## License
Internal use only - Fairness Factor
```

```text
# packages.txt
python3-dev
build-essential
git
curl
```

```text
# requirements.txt
streamlit==1.29.0
anthropic==0.8.1
python-dotenv==1.0.0
pymongo==4.6.1
dnspython==2.4.2
bcrypt==4.1.1
PyJWT==2.8.0
pandas==2.1.3
pytest==7.4.3
pytest-cov==4.1.0
python-multipart==0.0.6
watchdog==3.0.0
python-docx==1.0.1
PyPDF2==3.0.1
```

```text
# runtime.txt
python-3.9.16
```

================
File: requirements.txt
================
# requirements.txt
streamlit==1.29.0
anthropic==0.8.1
python-dotenv==1.0.0
motor==3.3.2
pymongo==4.6.1
dnspython==2.4.2
bcrypt==4.1.1
PyJWT==2.8.0
pandas==2.1.3
pytest==7.4.3
pytest-cov==4.1.0
python-multipart==0.0.6
watchdog==3.0.0
python-docx==1.0.1
PyPDF2==3.0.1
docx2txt2==1.0.4
Pillow==10.0.0
pyyaml==6.0.1
nest_asyncio==1.6.0

================
File: scripts/rotate_jwt_key.py
================
# scripts/rotate_jwt_key.py
import asyncio
import os
from dotenv import load_dotenv
from utils.mongo_manager import AsyncMongoManager
from utils.key_rotation import JWTKeyRotator
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def rotate_jwt_key():
    """Rotate JWT key and update environment"""
    try:
        # Initialize MongoDB connection
        mongo_manager = AsyncMongoManager()
        async with mongo_manager.get_connection() as (_, db, _):
            key_rotator = JWTKeyRotator(db)
            
            # Rotate key
            new_key_data = await key_rotator.rotate_key()
            
            # Update .env file
            env_path = '.env'
            temp_env_path = '.env.temp'
            
            with open(env_path, 'r') as env_file:
                env_contents = env_file.readlines()
            
            with open(temp_env_path, 'w') as temp_file:
                for line in env_contents:
                    if line.startswith('JWT_SECRET_KEY='):
                        temp_file.write(f'JWT_SECRET_KEY={new_key_data["key"]}\n')
                    else:
                        temp_file.write(line)
            
            # Replace old .env with new one
            os.replace(temp_env_path, env_path)
            
            # Clean up expired keys
            deleted_count = await key_rotator.cleanup_expired_keys()
            
            logger.info(f"JWT key rotated successfully. Expires: {new_key_data['expires_at']}")
            logger.info(f"Cleaned up {deleted_count} expired keys")
            
    except Exception as e:
        logger.error(f"Error rotating JWT key: {e}")
        raise

if __name__ == "__main__":
    load_dotenv()
    asyncio.run(rotate_jwt_key())

================
File: static/styles.css
================
/* static/styles.css */
:root {
    /* Primary Color Palette */
    --white: #ffffff;
    --black: #000000;
    --accent-orange: #FC510B;
    --dark-orange: #FF7500;
    --deep-orange: #FF5722;
    --primary-blue: #0075E0;
    --secondary-blue: #003A6E;
    --overlay-color: #CEF3FF;
    
    /* Global Colors */
    --accent-color-1: var(--e-global-color-ee3daea);
    --accent-color-2: var(--e-global-color-b2c6ea4);
}

/* Main app styling */
.stApp {
    background: linear-gradient(135deg, var(--primary-blue) 0%, var(--secondary-blue) 100%);
    color: var(--white);
}

/* Header styles */
.stApp > header {
    position: fixed;
    top: 0;
    z-index: 100;
    transition: background-color 0.3s ease;
}

.stApp > header.sticky {
    background-color: var(--white);
}

/* Logo containers */
.logo-container-login, .logo-container-main {
    text-align: center;
    padding: 1.5rem 0;
    margin-bottom: 2rem;
    transition: transform 0.3s ease;
}

.logo-container-login img,
.logo-container-main img {
    max-width: 240px;
    height: auto;
    transition: transform 0.3s ease;
}

/* Typography & Text Styles */
h1, h2, h3, h4, h5, h6 {
    font-weight: 700;
    color: var(--white);
}

.accent-color {
    color: var(--accent-orange);
}

/* Breadcrumbs */
.breadcrumb {
    display: flex;
    gap: 0.5rem;
    align-items: center;
}

.breadcrumb-item {
    color: var(--accent-orange);
    text-decoration: none;
}

.breadcrumb-item.active {
    color: var(--white);
}

/* Buttons */
.stButton > button {
    background-color: var(--accent-orange) !important;
    color: var(--white) !important;
    border: none !important;
    border-radius: 4px !important;
    padding: 0.75rem 1.5rem !important;
    font-weight: 600 !important;
    transition: all 0.3s ease !important;
}

.stButton > button:hover {
    background-color: var(--primary-blue) !important;
    transform: translateY(-1px);
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
}

/* Mission Section */
.mission-section {
    position: relative;
    overflow: hidden;
}

.mission-section::before {
    content: "";
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background: radial-gradient(circle at center, var(--overlay-color) 0%, transparent 70%);
    opacity: 0.1;
    pointer-events: none;
}

/* Cards */
.content-card {
    background: linear-gradient(135deg, var(--primary-blue) 0%, transparent 100%);
    padding: 2rem;
    border-radius: 8px;
    margin-bottom: 1.5rem;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
}

/* Form elements */
.stTextInput > div > div > input {
    border: 2px solid var(--accent-orange) !important;
    border-radius: 4px;
    padding: 0.75rem 1rem;
    transition: all 0.3s ease;
}

.stTextInput > div > div > input:focus {
    border-color: var(--primary-blue) !important;
    box-shadow: 0 0 0 2px rgba(0, 117, 224, 0.2);
}

/* Navigation items */
.nav-item {
    position: relative;
    padding: 0.5rem 1rem;
    transition: all 0.3s ease;
}

.nav-item:hover::before {
    content: "•";
    color: var(--accent-orange);
    position: absolute;
    left: -0.5rem;
}

/* Newsletter & Subscription Forms */
.newsletter-form {
    background-color: var(--white);
    padding: 2rem;
    border-radius: 8px;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
}

.newsletter-form button {
    background-color: var(--accent-orange);
    transition: background-color 0.3s ease;
}

.newsletter-form button:hover {
    background-color: var(--primary-blue);
}

/* Responsive adjustments */
@media screen and (max-width: 1036px) {
    .newsletter-form {
        display: flex;
        flex-direction: column;
        gap: 1rem;
    }

    .stButton > button {
        padding: 0.5rem 1rem !important;
    }

    .logo-container-login img,
    .logo-container-main img {
        max-width: 180px;
    }
}

/* User welcome message */
.user-welcome {
    color: var(--white);
    font-size: 1.1rem;
    padding: 1rem;
    margin-bottom: 1rem;
    text-align: center;
    font-weight: 500;
    background: rgba(255, 255, 255, 0.1);
    border-radius: 6px;
}

/* Page headers */
.page-header {
    color: var(--white);
    font-size: 2rem;
    font-weight: 700;
    margin: 1rem 0 2rem 0;
    padding-bottom: 1rem;
    border-bottom: 2px solid rgba(255, 255, 255, 0.1);
}

/* Footer */
.footer {
    text-align: center;
    padding: 2rem 0;
    margin-top: 4rem;
    border-top: 1px solid rgba(255, 255, 255, 0.1);
}

.footer p {
    color: var(--white);
    opacity: 0.8;
    font-size: 0.9rem;
}

/* Custom scrollbar */
::-webkit-scrollbar {
    width: 8px;
}

::-webkit-scrollbar-track {
    background: var(--secondary-blue);
}

::-webkit-scrollbar-thumb {
    background: var(--accent-orange);
    border-radius: 4px;
}

::-webkit-scrollbar-thumb:hover {
    background: var(--dark-orange);
}

/* Feature list */
.feature-list li::before {
    content: "•";
    color: var(--deep-orange);
    font-weight: bold;
    display: inline-block;
    width: 1em;
    margin-left: -1em;
}

/* Loading spinner */
.stSpinner {
    border-color: var(--accent-orange) !important;
}

================
File: test_auth.py
================
import asyncio
from motor.motor_asyncio import AsyncIOMotorClient
from urllib.parse import quote_plus
import logging
from dotenv import load_dotenv
import os

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_auth_levels():
    """Test MongoDB authentication with different permission levels"""
    try:
        load_dotenv()
        uri = os.getenv('MONGODB_URI')
        
        if not uri:
            logger.error("MongoDB URI not found in environment variables")
            return False
            
        logger.info("Testing connection with provided URI...")
        logger.info(f"URI format check: {uri.split('://')[0]}://<credentials>@{uri.split('@')[1]}")
        
        client = AsyncIOMotorClient(uri)
        db = client.fairness_factor_blog
        
        # Test 1: Basic Connection
        logger.info("\nTest 1: Testing basic connection...")
        try:
            await client.admin.command('ping')
            logger.info("✅ Basic connection successful")
        except Exception as e:
            logger.error(f"❌ Basic connection failed: {str(e)}")
            return False
            
        # Test 2: Read Permission
        logger.info("\nTest 2: Testing read permission...")
        try:
            collections = await db.list_collection_names()
            logger.info(f"✅ Read permission verified. Found collections: {collections}")
        except Exception as e:
            logger.error(f"❌ Read permission failed: {str(e)}")
            
        # Test 3: Write Permission
        logger.info("\nTest 3: Testing write permission...")
        try:
            result = await db.test_collection.insert_one({"test": "data"})
            logger.info("✅ Write permission verified")
            await db.test_collection.delete_one({"test": "data"})
        except Exception as e:
            logger.error(f"❌ Write permission failed: {str(e)}")
            
        # Test 4: Index Creation
        logger.info("\nTest 4: Testing index creation permission...")
        try:
            await db.test_collection.create_index([("test_field", 1)])
            logger.info("✅ Index creation permission verified")
        except Exception as e:
            logger.error(f"❌ Index creation failed: {str(e)}")
            
        logger.info("\nPermission test summary:")
        logger.info("Please ensure your MongoDB user has:")
        logger.info("1. readWrite role on the database")
        logger.info("2. dbAdmin role for index management")
        logger.info("\nTo fix permissions in MongoDB Atlas:")
        logger.info("1. Go to Database Access")
        logger.info("2. Edit user 'KrypticGadget'")
        logger.info("3. Add 'readWrite' and 'dbAdmin' roles for database 'fairness_factor_blog'")
        
        return True
        
    except Exception as e:
        logger.error(f"❌ Overall test failed: {str(e)}")
        return False
        
    finally:
        if 'client' in locals():
            client.close()

if __name__ == "__main__":
    asyncio.run(test_auth_levels())

================
File: test_mongodb_connection.py
================
import asyncio
from motor.motor_asyncio import AsyncIOMotorClient
from urllib.parse import quote_plus
import logging
from dotenv import load_dotenv
import os

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_mongodb_connection():
    """Test MongoDB connection with updated URI format"""
    try:
        # Connection parameters
        username = "KrypticGadget"
        password = "1629609804"  # In production, get from environment
        cluster = "fairness-factor-cluster.p0tsa.mongodb.net"
        
        # Properly escape credentials
        username = quote_plus(username)
        password = quote_plus(password)
        
        # Construct URI with updated format
        uri = f"mongodb+srv://{username}:{password}@{cluster}/?retryWrites=true&w=majority&appName=fairness-factor-cluster"
        
        logger.info("Testing connection with new URI format...")
        client = AsyncIOMotorClient(uri)
        
        # Test basic connection
        logger.info("Testing basic connection...")
        await client.admin.command('ping')
        logger.info("✅ Basic connection successful!")
        
        # Select database
        db = client.fairness_factor_blog
        logger.info("Selecting database: fairness_factor_blog")
        
        # Test database operations
        logger.info("Testing database operations...")
        try:
            # Test read
            collections = await db.list_collection_names()
            logger.info(f"📚 Existing collections: {collections}")
            
            # Test write
            result = await db.connection_test.insert_one({"test": "data"})
            logger.info("✅ Write test successful")
            await db.connection_test.delete_one({"test": "data"})
            logger.info("✅ Delete test successful")
            
            # Test index creation
            await db.connection_test.create_index([("test_field", 1)])
            logger.info("✅ Index creation successful")
            
            return True
            
        except Exception as e:
            logger.error(f"❌ Database operation failed: {str(e)}")
            logger.info("\nTroubleshooting steps:")
            logger.info("1. Verify user permissions in MongoDB Atlas")
            logger.info("2. Check database name is correct")
            logger.info("3. Ensure IP whitelist includes your current IP")
            return False
            
    except Exception as e:
        logger.error(f"❌ Connection failed: {str(e)}")
        return False
        
    finally:
        if 'client' in locals():
            client.close()

if __name__ == "__main__":
    asyncio.run(test_mongodb_connection())

================
File: test_mongodb.py
================
import asyncio
from motor.motor_asyncio import AsyncIOMotorClient
import logging
from dotenv import load_dotenv
import os

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_connection():
    """Test MongoDB connection"""
    try:
        load_dotenv()
        uri = os.getenv('MONGODB_URI')
        
        if not uri:
            logger.error("MongoDB URI not found in environment variables")
            return False
            
        client = AsyncIOMotorClient(uri)
        
        # Test connection
        await client.admin.command('ping')
        logger.info("✅ Successfully connected to MongoDB!")
        
        # Get database
        db = client.fairness_factor_blog
        
        # List collections
        collections = await db.list_collection_names()
        logger.info(f"📚 Available collections: {collections}")
        
        return True
        
    except Exception as e:
        logger.error(f"❌ Connection error: {str(e)}")
        return False
    
    finally:
        if 'client' in locals():
            client.close()

# For direct script execution
if __name__ == "__main__":
    asyncio.run(test_connection())

================
File: tests/test_mongodb.py
================
# tests/test_mongodb.py
import pytest
from unittest.mock import Mock, patch
import os
from datetime import datetime
from bson import ObjectId
from utils.mongo_manager import MongoManager, get_db_context
from utils.data_handlers import BlogContentHandler, FileHandler, SessionHandler, AnalyticsHandler

@pytest.fixture
def mock_mongo_client():
    with patch('pymongo.MongoClient') as mock_client:
        mock_db = Mock()
        mock_fs = Mock()
        mock_client.return_value.fairness_factor_blog = mock_db
        mock_client.return_value.admin.command = Mock()
        yield mock_client, mock_db, mock_fs

@pytest.fixture
def mock_db_context(mock_mongo_client):
    mock_client, mock_db, mock_fs = mock_mongo_client
    with patch('utils.mongo_manager.MongoManager') as mock_manager:
        mock_manager.return_value.get_connection.return_value = (mock_client, mock_db, mock_fs)
        yield mock_db

class TestMongoManager:
    def test_singleton_instance(self):
        manager1 = MongoManager()
        manager2 = MongoManager()
        assert manager1 is manager2

    def test_connection_error_handling(self, mock_mongo_client):
        mock_client, _, _ = mock_mongo_client
        mock_client.side_effect = Exception("Connection failed")
        
        with pytest.raises(Exception) as exc_info:
            MongoManager()
        assert "Connection failed" in str(exc_info.value)

class TestBlogContentHandler:
    @pytest.fixture
    def blog_handler(self, mock_db_context):
        return BlogContentHandler(mock_db_context)

    def test_save_research(self, blog_handler, mock_db_context):
        mock_db_context.blog_content.insert_one.return_value = Mock(inserted_id=ObjectId())
        
        result = blog_handler.save_research(
            user_email="test@fairnessfactor.com",
            document_contents=["test content"],
            analysis="test analysis"
        )
        
        assert isinstance(result, str)
        assert mock_db_context.blog_content.insert_one.called

    def test_get_user_content(self, blog_handler, mock_db_context):
        expected_content = [{"_id": ObjectId(), "content": "test"}]
        mock_db_context.blog_content.find.return_value.sort.return_value = expected_content
        
        result = blog_handler.get_user_content("test@fairnessfactor.com")
        
        assert result == expected_content
        assert mock_db_context.blog_content.find.called

# Add more test classes and methods as needed

================
File: utils/__init__.py
================
# utils/__init__.py
from .auth import AsyncAuthHandler
from .mongo_manager import AsyncMongoManager
from .data_handlers import AsyncBlogContentHandler, AsyncFileHandler, AsyncAnalyticsHandler
from .prompt_handler import AsyncPromptHandler
from .session_manager import AsyncSessionManager

__all__ = [
    'AsyncAuthHandler',
    'AsyncMongoManager',
    'AsyncBlogContentHandler',
    'AsyncFileHandler',
    'AsyncAnalyticsHandler',
    'AsyncPromptHandler',
    'AsyncSessionManager'
]

================
File: utils/auth_handler.py
================
# utils/auth_handler.py
import os
import jwt
import bcrypt
from datetime import datetime, timedelta
import logging
from typing import Optional, Dict, Any
import asyncio
from motor.motor_asyncio import AsyncIOMotorDatabase

logger = logging.getLogger(__name__)

class AsyncAuthHandler:
    def __init__(self, db: AsyncIOMotorDatabase):
        self.secret_key = os.getenv('JWT_SECRET_KEY')
        if not self.secret_key:
            raise ValueError("JWT_SECRET_KEY not found in environment variables")
        self.db = db
        self.users_collection = db.users
        asyncio.create_task(self._ensure_admin_user())

    async def _ensure_admin_user(self):
        """Ensure admin user exists"""
        admin_email = 'zack@fairnessfactor.com'
        admin_exists = await self.users_collection.find_one({'email': admin_email})
        
        if not admin_exists:
            salt = bcrypt.gensalt()
            hashed_password = bcrypt.hashpw("1122Kryptic$".encode('utf-8'), salt)
            
            await self.users_collection.insert_one({
                'email': admin_email,
                'password': hashed_password,
                'name': 'Admin User',
                'role': 'admin',
                'created_at': datetime.now(),
                'created_by': 'system'
            })
            logger.info("Created default admin user")

    async def verify_email_domain(self, email: str) -> bool:
        """Verify email belongs to Fairness Factor domain."""
        email = email.lower()
        return email.endswith('fairnessfactor.com')

    async def add_user(
        self, 
        email: str, 
        password: str, 
        name: str, 
        added_by: str, 
        role: str = 'user'
    ) -> bool:
        """Add a new user to the system."""
        try:
            if not await self.verify_email_domain(email):
                raise ValueError("Only Fairness Factor email addresses are allowed")

            existing_user = await self.users_collection.find_one({'email': email.lower()})
            if existing_user:
                raise ValueError("User already exists")

            salt = bcrypt.gensalt()
            hashed = bcrypt.hashpw(password.encode('utf-8'), salt)

            await self.users_collection.insert_one({
                'email': email.lower(),
                'password': hashed,
                'name': name,
                'role': role,
                'created_at': datetime.now(),
                'created_by': added_by
            })
            return True

        except Exception as e:
            logger.error(f"Error adding user {email}: {str(e)}")
            raise

    async def login(self, email: str, password: str) -> Optional[str]:
        """Authenticate user and return JWT token."""
        try:
            user = await self.users_collection.find_one({'email': email.lower()})
            if not user:
                return None

            stored_password = user['password']
            if isinstance(stored_password, str):
                stored_password = stored_password.encode('utf-8')

            if bcrypt.checkpw(password.encode('utf-8'), stored_password):
                token = jwt.encode({
                    'email': user['email'],
                    'name': user['name'],
                    'role': user.get('role', 'user'),
                    'exp': datetime.utcnow() + timedelta(days=1)
                }, self.secret_key, algorithm='HS256')

                # Log successful login
                await self.db.login_history.insert_one({
                    'user_email': user['email'],
                    'timestamp': datetime.now(),
                    'success': True
                })

                return token

            # Log failed login attempt
            await self.db.login_history.insert_one({
                'user_email': email,
                'timestamp': datetime.now(),
                'success': False,
                'reason': 'invalid_password'
            })
            return None

        except Exception as e:
            logger.error(f"Login error for {email}: {str(e)}")
            return None

    async def verify_token(self, token: str) -> Optional[Dict[str, Any]]:
        """Verify JWT token and return user info."""
        try:
            payload = jwt.decode(token, self.secret_key, algorithms=['HS256'])
            user = await self.users_collection.find_one({'email': payload['email']})

            if user:
                return {
                    'email': user['email'],
                    'name': user['name'],
                    'role': user.get('role', 'user')
                }

            return None

        except jwt.ExpiredSignatureError:
            return None
        except jwt.InvalidTokenError:
            return None
        except Exception as e:
            logger.error(f"Token verification error: {str(e)}")
            return None

    async def get_user_sessions(self, user_email: str) -> List[Dict[str, Any]]:
        """Get user's session history"""
        try:
            cursor = self.db.login_history.find(
                {'user_email': user_email}
            ).sort('timestamp', -1).limit(10)
            return await cursor.to_list(length=None)
        except Exception as e:
            logger.error(f"Error retrieving user sessions: {str(e)}")
            return []

================
File: utils/auth.py
================
# utils/auth.py
import os
import asyncio
from datetime import datetime, timedelta
import logging
import jwt
import bcrypt
from motor.motor_asyncio import AsyncIOMotorDatabase
from typing import Optional, Dict, Any, List
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)

class AsyncAuthHandler:
    def __init__(self, db: AsyncIOMotorDatabase):
        self.db = db
        self.secret_key = os.getenv('JWT_SECRET_KEY')
        if not self.secret_key:
            raise ValueError("JWT_SECRET_KEY not found in environment variables")
        self.users_collection = db.users
        self.login_history_collection = db.login_history

    async def verify_email_domain(self, email: str) -> bool:
        """Verify email belongs to Fairness Factor domain."""
        return email.lower().endswith('@fairnessfactor.com')

    async def add_user(
        self,
        email: str,
        password: str,
        name: str,
        added_by: str,
        role: str = 'user'
    ) -> bool:
        """Add a new user to the system."""
        try:
            if not await self.verify_email_domain(email):
                raise ValueError("Only Fairness Factor email addresses are allowed")

            existing_user = await self.users_collection.find_one({'email': email.lower()})
            if existing_user:
                raise ValueError("User already exists")

            # Get current event loop
            loop = asyncio.get_running_loop()
            
            # Run bcrypt operations in executor
            salt = await loop.run_in_executor(None, bcrypt.gensalt)
            hashed = await loop.run_in_executor(None, bcrypt.hashpw, password.encode('utf-8'), salt)

            await self.users_collection.insert_one({
                'email': email.lower(),
                'password': hashed,
                'name': name,
                'role': role,
                'created_at': datetime.now(),
                'created_by': added_by
            })
            return True
        except Exception as e:
            logger.error(f"Error adding user {email}: {str(e)}")
            raise

    async def login(self, email: str, password: str) -> Optional[str]:
        """Authenticate user and return JWT token."""
        try:
            # Get current event loop
            loop = asyncio.get_running_loop()
            
            user = await self.users_collection.find_one({'email': email.lower()})
            if not user:
                return None

            stored_password = user['password']
            if isinstance(stored_password, str):
                stored_password = stored_password.encode('utf-8')

            # Run password check in executor to avoid blocking
            is_valid = await loop.run_in_executor(
                None, 
                bcrypt.checkpw,
                password.encode('utf-8'),
                stored_password
            )

            if is_valid:
                token = jwt.encode({
                    'email': user['email'],
                    'name': user['name'],
                    'role': user.get('role', 'user'),
                    'exp': datetime.utcnow() + timedelta(days=1)
                }, self.secret_key, algorithm='HS256')

                # Log successful login
                await self.login_history_collection.insert_one({
                    'user_email': user['email'],
                    'timestamp': datetime.now(),
                    'success': True
                })
                return token

            # Log failed login
            await self.login_history_collection.insert_one({
                'user_email': email,
                'timestamp': datetime.now(),
                'success': False,
                'reason': 'invalid_password'
            })
            return None

        except Exception as e:
            logger.error(f"Login error for {email}: {str(e)}")
            return None

    async def verify_token(self, token: str) -> Optional[Dict[str, Any]]:
        """Verify JWT token and return user info."""
        try:
            # Get current event loop
            loop = asyncio.get_running_loop()
            
            # Run JWT decode in executor
            payload = await loop.run_in_executor(
                None,
                jwt.decode,
                token,
                self.secret_key,
                algorithms=['HS256']
            )
            
            user = await self.users_collection.find_one({'email': payload['email']})
            if user:
                return {
                    'email': user['email'],
                    'name': user['name'],
                    'role': user.get('role', 'user')
                }
            return None
        except jwt.ExpiredSignatureError:
            logger.warning("Token expired")
            return None
        except jwt.InvalidTokenError:
            logger.warning("Invalid token")
            return None
        except Exception as e:
            logger.error(f"Token verification error: {str(e)}")
            return None

    async def get_user_sessions(self, user_email: str) -> List[Dict[str, Any]]:
        """Get user's session history"""
        try:
            cursor = self.login_history_collection.find(
                {'user_email': user_email}
            ).sort('timestamp', -1).limit(10)
            return await cursor.to_list(length=None)
        except Exception as e:
            logger.error(f"Error retrieving user sessions: {str(e)}")
            return []

    async def get_user(self, email: str) -> Optional[Dict[str, Any]]:
        """Get user information."""
        try:
            user = await self.users_collection.find_one({'email': email.lower()})
            if user:
                return {
                    'email': user['email'],
                    'name': user['name'],
                    'role': user.get('role', 'user'),
                    'created_at': user['created_at']
                }
            return None
        except Exception as e:
            logger.error(f"Error retrieving user {email}: {str(e)}")
            return None

    async def change_password(self, email: str, current_password: str, new_password: str) -> bool:
        """Change user password."""
        try:
            # Get current event loop
            loop = asyncio.get_running_loop()
            
            user = await self.users_collection.find_one({'email': email.lower()})
            if not user:
                return False

            stored_password = user['password']
            if isinstance(stored_password, str):
                stored_password = stored_password.encode('utf-8')

            # Run password check in executor
            is_valid = await loop.run_in_executor(
                None,
                bcrypt.checkpw,
                current_password.encode('utf-8'),
                stored_password
            )

            if is_valid:
                # Generate new password hash in executor
                salt = await loop.run_in_executor(None, bcrypt.gensalt)
                new_hashed = await loop.run_in_executor(
                    None,
                    bcrypt.hashpw,
                    new_password.encode('utf-8'),
                    salt
                )
                
                result = await self.users_collection.update_one(
                    {'email': email.lower()},
                    {'$set': {'password': new_hashed}}
                )
                return result.modified_count > 0
            return False
        except Exception as e:
            logger.error(f"Password change error for {email}: {str(e)}")
            return False

================
File: utils/data_handlers.py
================
# utils/data_handlers.py
from datetime import datetime
from bson import ObjectId
import logging
from typing import Optional, List, Dict, Any
import pandas as pd
import io
import asyncio

logger = logging.getLogger(__name__)

class AsyncBlogContentHandler:
    def __init__(self, db):
        self.db = db
        self.collection = db.blog_content

    async def save_research(self, user_email: str, document_contents: List[str], analysis: str) -> str:
        try:
            document = {
                'type': 'research',
                'user_email': user_email,
                'document_contents': document_contents,
                'analysis': analysis,
                'created_at': datetime.now(),
                'updated_at': datetime.now()
            }
            result = await self.collection.insert_one(document)
            return str(result.inserted_id)
        except Exception as e:
            logger.error(f"Error saving research: {e}")
            raise

    async def save_article_draft(
        self, 
        user_email: str, 
        research_id: str, 
        content: str, 
        metadata: Dict[str, Any]
    ) -> str:
        try:
            document = {
                'type': 'draft',
                'user_email': user_email,
                'research_id': research_id,
                'content': content,
                'metadata': metadata,
                'created_at': datetime.now(),
                'updated_at': datetime.now()
            }
            result = await self.collection.insert_one(document)
            return str(result.inserted_id)
        except Exception as e:
            logger.error(f"Error saving article draft: {e}")
            raise

    async def get_user_content(
        self, 
        user_email: str, 
        content_type: Optional[str] = None,
        limit: int = 100
    ) -> List[Dict]:
        try:
            query = {'user_email': user_email}
            if content_type:
                query['type'] = content_type
            cursor = self.collection.find(query).sort('created_at', -1).limit(limit)
            return await cursor.to_list(length=None)
        except Exception as e:
            logger.error(f"Error retrieving user content: {e}")
            return []

    async def update_content(
        self, 
        content_id: str, 
        updates: Dict[str, Any]
    ) -> bool:
        try:
            updates['updated_at'] = datetime.now()
            result = await self.collection.update_one(
                {'_id': ObjectId(content_id)},
                {'$set': updates}
            )
            return result.modified_count > 0
        except Exception as e:
            logger.error(f"Error updating content: {e}")
            return False

class AsyncFileHandler:
    def __init__(self, fs):
        self.fs = fs

    async def save_file(
        self, 
        filename: str, 
        file_data: bytes, 
        metadata: Dict[str, Any]
    ) -> str:
        try:
            file_id = await self.fs.upload_from_stream(
                filename,
                file_data,
                metadata={
                    **metadata,
                    'uploaded_at': datetime.now()
                }
            )
            return str(file_id)
        except Exception as e:
            logger.error(f"Error saving file: {e}")
            raise

    async def get_file(self, file_id: str) -> Optional[bytes]:
        try:
            grid_out = await self.fs.open_download_stream(ObjectId(file_id))
            return await grid_out.read()
        except Exception as e:
            logger.error(f"Error retrieving file: {e}")
            return None

class AsyncAnalyticsHandler:
    def __init__(self, db):
        self.db = db
        self.collection = db.analytics

    async def log_activity(
        self, 
        user_email: str, 
        activity_type: str, 
        metadata: Dict[str, Any]
    ) -> None:
        try:
            document = {
                'user_email': user_email,
                'activity_type': activity_type,
                'metadata': metadata,
                'timestamp': datetime.now()
            }
            await self.collection.insert_one(document)
        except Exception as e:
            logger.error(f"Error logging activity: {e}")

    async def get_user_analytics(
        self, 
        user_email: str, 
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None
    ) -> List[Dict]:
        try:
            pipeline = [
                {'$match': {
                    'user_email': user_email,
                    **({'timestamp': {
                        '$gte': start_date,
                        '$lte': end_date
                    }} if start_date and end_date else {})
                }},
                {'$group': {
                    '_id': '$activity_type',
                    'count': {'$sum': 1},
                    'last_activity': {'$max': '$timestamp'}
                }}
            ]
            cursor = self.collection.aggregate(pipeline)
            return await cursor.to_list(length=None)
        except Exception as e:
            logger.error(f"Error retrieving analytics: {e}")
            return []

================
File: utils/key_rotation.py
================
# utils/key_rotation.py
import secrets
import jwt
from datetime import datetime, timedelta
import logging
from typing import Optional, Dict, Any

logger = logging.getLogger(__name__)

class JWTKeyRotator:
    def __init__(self, db):
        self.db = db
        self.keys_collection = db.jwt_keys

    async def generate_new_key(self) -> str:
        """Generate a new JWT secret key"""
        return secrets.token_hex(32)

    async def store_key(self, key: str, expiry_days: int = 30) -> str:
        """Store a new JWT key with expiration"""
        try:
            key_doc = {
                'key': key,
                'created_at': datetime.utcnow(),
                'expires_at': datetime.utcnow() + timedelta(days=expiry_days),
                'is_active': True
            }
            result = await self.keys_collection.insert_one(key_doc)
            return str(result.inserted_id)
        except Exception as e:
            logger.error(f"Error storing JWT key: {e}")
            raise

    async def rotate_key(self, expiry_days: int = 30) -> Dict[str, Any]:
        """Generate and store a new key while deprecating the old one"""
        try:
            # Generate new key
            new_key = await self.generate_new_key()
            
            # Store new key
            new_key_id = await self.store_key(new_key, expiry_days)
            
            # Deactivate old keys
            await self.keys_collection.update_many(
                {'_id': {'$ne': new_key_id}},
                {'$set': {'is_active': False}}
            )
            
            return {
                'key_id': new_key_id,
                'key': new_key,
                'expires_at': datetime.utcnow() + timedelta(days=expiry_days)
            }
        except Exception as e:
            logger.error(f"Error rotating JWT key: {e}")
            raise

    async def get_active_key(self) -> Optional[str]:
        """Get the current active JWT key"""
        try:
            key_doc = await self.keys_collection.find_one(
                {
                    'is_active': True,
                    'expires_at': {'$gt': datetime.utcnow()}
                }
            )
            return key_doc['key'] if key_doc else None
        except Exception as e:
            logger.error(f"Error retrieving active JWT key: {e}")
            return None

    async def cleanup_expired_keys(self) -> int:
        """Remove expired keys from the database"""
        try:
            result = await self.keys_collection.delete_many(
                {'expires_at': {'$lt': datetime.utcnow()}}
            )
            return result.deleted_count
        except Exception as e:
            logger.error(f"Error cleaning up expired JWT keys: {e}")
            return 0

================
File: utils/mongo_manager.py
================
# utils/mongo_manager.py
import os
import motor.motor_asyncio
import asyncio
from typing import Optional, Tuple, Any
from threading import Lock
import logging
import gridfs
from motor.motor_asyncio import AsyncIOMotorGridFSBucket

logger = logging.getLogger(__name__)

class AsyncMongoManager:
    _instance = None
    _lock = Lock()

    def __new__(cls):
        with cls._lock:
            if cls._instance is None:
                cls._instance = super(AsyncMongoManager, cls).__new__(cls)
                cls._instance._initialized = False
            return cls._instance

    def __init__(self):
        if self._initialized:
            return
            
        self._initialized = True
        self.client = None
        self.db = None
        self.fs = None
        
        # Remove this line
        # asyncio.create_task(self._connect())
        
        # Instead, initialize connection in an async context
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(self._connect())

    async def _connect(self) -> None:
        """Establish async connection to MongoDB"""
        try:
            uri = os.getenv('MONGODB_URI')
            if not uri:
                raise ValueError("MONGODB_URI not found in environment variables")

            self.client = motor.motor_asyncio.AsyncIOMotorClient(uri)
            self.db = self.client.fairness_factor_blog
            self.fs = AsyncIOMotorGridFSBucket(self.db)
            
            # Test connection
            await self.client.admin.command('ping')
            logger.info("Successfully connected to MongoDB")

            # Create indexes
            await self._create_indexes()

        except Exception as e:
            logger.error(f"Failed to connect to MongoDB: {e}")
            raise

    async def _create_indexes(self):
        """Create necessary indexes"""
        try:
            # Blog content indexes
            await self.db.blog_content.create_index([("user_email", 1)])
            await self.db.blog_content.create_index([("created_at", -1)])
            await self.db.blog_content.create_index([("type", 1)])

            # User session indexes
            await self.db.user_sessions.create_index([("user_email", 1)])
            await self.db.user_sessions.create_index([("created_at", -1)])

            # Analytics indexes
            await self.db.analytics.create_index([("user_email", 1)])
            await self.db.analytics.create_index([("timestamp", -1)])
            await self.db.analytics.create_index([("activity_type", 1)])

            # LLM logs indexes
            await self.db.llm_logs.create_index([("user_email", 1)])
            await self.db.llm_logs.create_index([("timestamp", -1)])

            logger.info("Successfully created MongoDB indexes")

        except Exception as e:
            logger.error(f"Failed to create indexes: {e}")
            raise

    async def get_connection(self):
        """Get async database connection"""
        if not self.client:
            await self._connect()
        return self.client, self.db

    async def get_fs(self):
        """Get GridFS bucket"""
        if not self.fs:
            await self._connect()
        return self.fs

    async def close(self):
        """Close MongoDB connection"""
        if self.client:
            self.client.close()
            self.client = None
            self.db = None
            self.fs = None

class AsyncDatabaseSession:
    """Async context manager for database sessions"""
    
    def __init__(self):
        self.mongo_manager = AsyncMongoManager()
        self.client = None
        self.db = None
        self.fs = None

    async def __aenter__(self):
        self.client, self.db = await self.mongo_manager.get_connection()
        self.fs = await self.mongo_manager.get_fs()
        return self.client, self.db, self.fs

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        # Connection handled by MongoManager
        pass

def get_db_session():
    """Get database session for use in application"""
    return AsyncDatabaseSession()

================
File: utils/prompt_handler.py
================
# utils/prompt_handler.py
import os
from typing import Optional, Dict, Any
import logging
import json
from datetime import datetime

logger = logging.getLogger(__name__)

class AsyncPromptHandler:
    def __init__(self, db):
        self.db = db
        self.prompts_collection = db.prompts

    async def load_prompt(self, prompt_name: str) -> Optional[str]:
        """Load prompt template from database or file system"""
        try:
            # Try to load from database first
            prompt_doc = await self.prompts_collection.find_one({'name': prompt_name})
            if prompt_doc:
                return prompt_doc['content']

            # Fall back to file system
            prompt_path = f"prompts/{prompt_name}.txt"
            if os.path.exists(prompt_path):
                with open(prompt_path, 'r') as f:
                    content = f.read()
                    # Store in database for future use
                    await self.prompts_collection.insert_one({
                        'name': prompt_name,
                        'content': content,
                        'created_at': datetime.now()
                    })
                    return content
            
            raise FileNotFoundError(f"Prompt template {prompt_name} not found")
            
        except Exception as e:
            logger.error(f"Error loading prompt {prompt_name}: {str(e)}")
            return None

    async def format_prompt(
        self, 
        prompt_name: str, 
        variables: Dict[str, Any]
    ) -> Optional[str]:
        """Load and format prompt template with variables"""
        try:
            template = await self.load_prompt(prompt_name)
            if not template:
                return None

            # Format prompt with variables
            formatted_prompt = template
            for key, value in variables.items():
                formatted_prompt = formatted_prompt.replace(f"{{{key}}}", str(value))

            return formatted_prompt

        except Exception as e:
            logger.error(f"Error formatting prompt {prompt_name}: {str(e)}")
            return None

    async def save_prompt_history(
        self, 
        prompt_name: str, 
        variables: Dict[str, Any], 
        formatted_prompt: str,
        user_email: str
    ) -> Optional[str]:
        """Save prompt usage history"""
        try:
            result = await self.db.prompt_history.insert_one({
                'prompt_name': prompt_name,
                'variables': variables,
                'formatted_prompt': formatted_prompt,
                'user_email': user_email,
                'timestamp': datetime.now()
            })
            return str(result.inserted_id)
        except Exception as e:
            logger.error(f"Error saving prompt history: {str(e)}")
            return None

================
File: utils/session_manager.py
================
# utils/session_manager.py
from datetime import datetime
import logging
from typing import Optional, Dict, Any, List  # Add List to the imports
from motor.motor_asyncio import AsyncIOMotorDatabase
from bson import ObjectId  # Add this import for ObjectId

logger = logging.getLogger(__name__)

class AsyncSessionManager:
    def __init__(self, db: AsyncIOMotorDatabase):
        self.db = db
        self.sessions_collection = db.sessions

    async def create_session(
        self, 
        user_email: str, 
        session_data: Dict[str, Any]
    ) -> Optional[str]:
        try:
            result = await self.sessions_collection.insert_one({
                'user_email': user_email,
                'data': session_data,
                'created_at': datetime.now(),
                'last_accessed': datetime.now(),
                'active': True
            })
            return str(result.inserted_id)
        except Exception as e:
            logger.error(f"Error creating session: {str(e)}")
            return None

    async def update_session(
        self, 
        session_id: str, 
        session_data: Dict[str, Any]
    ) -> bool:
        try:
            result = await self.sessions_collection.update_one(
                {'_id': ObjectId(session_id)},
                {
                    '$set': {
                        'data': session_data,
                        'last_accessed': datetime.now()
                    }
                }
            )
            return result.modified_count > 0
        except Exception as e:
            logger.error(f"Error updating session: {str(e)}")
            return False

    async def end_session(self, session_id: str) -> bool:
        try:
            result = await self.sessions_collection.update_one(
                {'_id': ObjectId(session_id)},
                {
                    '$set': {
                        'active': False,
                        'ended_at': datetime.now()
                    }
                }
            )
            return result.modified_count > 0
        except Exception as e:
            logger.error(f"Error ending session: {str(e)}")
            return False

    async def get_active_sessions(self, user_email: str) -> List[Dict[str, Any]]:
        try:
            cursor = self.sessions_collection.find({
                'user_email': user_email,
                'active': True
            }).sort('last_accessed', -1)
            return await cursor.to_list(length=None)
        except Exception as e:
            logger.error(f"Error retrieving active sessions: {str(e)}")
            return []
